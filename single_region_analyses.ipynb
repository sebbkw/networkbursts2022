{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from utilities import *\n",
    "from recording_data import RECORDINGS\n",
    "from clustering import (\n",
    "    feature_vector_labels, feature_vector_labels_full,\n",
    "    get_feature_vectors, get_cluster_labels, sort_bursts_by_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open previously saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_processed_recordings = open_data('') # Path to processed data (pickle file format)\n",
    "processed_recordings_mua = open_data('') # Path to processed data (pickle file format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['thalamus', 'cortex', 'striatum']:\n",
    "    all_bursts, all_features = get_feature_vectors (\n",
    "        rms_processed_recordings,\n",
    "        processed_recordings_mua,\n",
    "        key=key+'_bursts', mua_key=key+'_mua'\n",
    "    )\n",
    "    \n",
    "    labels, pca = get_cluster_labels(all_features)\n",
    "    feature_list_ngb, feature_list_sb, bursts_ngb, bursts_sb = sort_bursts_by_labels(\n",
    "        all_bursts, all_features, labels\n",
    "    )\n",
    "    \n",
    "    if key == 'thalamus':\n",
    "        thalamus_ngb_features = feature_list_ngb\n",
    "        thalamus_sb_features = feature_list_sb\n",
    "        thalamus_ngb = bursts_ngb\n",
    "        thalamus_sb = bursts_sb\n",
    "    if key == 'striatum':\n",
    "        striatum_ngb_features = feature_list_ngb\n",
    "        striatum_sb_features = feature_list_sb\n",
    "        striatum_ngb = bursts_ngb\n",
    "        striatum_sb = bursts_sb\n",
    "    if key == 'cortex':\n",
    "        cortex_ngb_features = feature_list_ngb\n",
    "        cortex_sb_features = feature_list_sb\n",
    "        cortex_ngb = bursts_ngb\n",
    "        cortex_sb = bursts_sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature vector distributions across groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'cortex'\n",
    "\n",
    "all_bursts, all_features = get_feature_vectors(\n",
    "    rms_processed_recordings,\n",
    "    processed_recordings_mua,\n",
    "    key=key+'_bursts', mua_key=key+'_mua'\n",
    ")\n",
    "all_labels, _ = get_cluster_labels(all_features)\n",
    "feature_list_g1, feature_list_g2, bursts_g1, bursts_g2 = sort_bursts_by_labels(\n",
    "    all_bursts, all_features, all_labels\n",
    ")\n",
    "\n",
    "psd_data = {\n",
    "    \"NGB_f\": [],\n",
    "    \"NGB_Pxx\": [],\n",
    "    \"NGB_Pxx_stderr\": [],\n",
    "    \"SB_f\": [],\n",
    "    \"SB_Pxx\": [],\n",
    "    \"SB_Pxx_stderr\": []\n",
    "}\n",
    "\n",
    "f, Pxx_mean, Pxx_stderr = get_mean_psd(bursts_g1)\n",
    "plt.plot(f, Pxx_mean, label='NGB', c='tab:blue')\n",
    "plt.fill_between(f, Pxx_mean+Pxx_stderr, Pxx_mean-Pxx_stderr, alpha=0.5)\n",
    "\n",
    "psd_data[\"NGB_f\"] = f\n",
    "psd_data[\"NGB_Pxx\"] = Pxx_mean\n",
    "psd_data[\"NGB_Pxx_stderr\"] = Pxx_stderr\n",
    "\n",
    "f, Pxx_mean, Pxx_stderr = get_mean_psd(bursts_g2)\n",
    "plt.plot(f, Pxx_mean, label='SB', c='tab:red')\n",
    "plt.fill_between(f, Pxx_mean+Pxx_stderr, Pxx_mean-Pxx_stderr, alpha=0.5)\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Relative power ($\\mathregular{P/P_0}$)')\n",
    "\n",
    "psd_data[\"SB_f\"] = f\n",
    "psd_data[\"SB_Pxx\"] = Pxx_mean\n",
    "psd_data[\"SB_Pxx_stderr\"] = Pxx_stderr\n",
    "\n",
    "format_plot(plt.gca())\n",
    "plt.show()\n",
    "\n",
    "def cohen_d_for_welch (a, b):\n",
    "    return (np.mean(a) - np.mean(b)) / np.sqrt((np.var(a) + np.var(b)) / 2)\n",
    "\n",
    "tabulated_data = {\n",
    "    'feature': [],\n",
    "    'NGB mean (SEM)': [],\n",
    "    'SB mean (SEM)': [],\n",
    "    'df': [],\n",
    "    'Welch’s t': [],\n",
    "    'p': [],\n",
    "    'Cohen’s d': []\n",
    "}\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=[20,10])\n",
    "axs = axs.reshape(-1)\n",
    "for feature_idx, feature_label in enumerate(feature_vector_labels_full):        \n",
    "    f_g1 = [f[feature_idx] for f in feature_list_g1]\n",
    "    f_g2 = [f[feature_idx] for f in feature_list_g2]\n",
    "    \n",
    "    print('N ngb =', len(f_g1), 'sb = ',len(f_g2), 'uc =', len(all_features[all_labels == 2]))\n",
    "    \n",
    "    weights = [np.ones(len(f_g1)) / float(len(f_g1)), np.ones(len(f_g2)) / float(len(f_g2))]\n",
    "    \n",
    "    axs[feature_idx].hist([f_g1, f_g2], label=['NGB', 'SB'], color=['tab:blue', 'tab:red'], weights=weights)\n",
    "    axs[feature_idx].set_xlabel(feature_label)\n",
    "    axs[feature_idx].set_ylabel('Density')\n",
    "    axs[feature_idx].set_ylim(0,1)\n",
    "    \n",
    "    format_plot(axs[feature_idx], legend=False, size=[17.5, 20])\n",
    "    \n",
    "    print('\\n', feature_label)\n",
    "    print('Mean ngb =', np.mean(f_g1), 'sb =', np.mean(f_g2))\n",
    "    print('Std ngb =', np.std(f_g1), 'sb =', np.std(f_g2))\n",
    "    print(stats.ttest_ind(f_g1, f_g2, equal_var=False))\n",
    "    print('Cohen\\'s d =', cohen_d_for_welch(f_g1, f_g2))\n",
    "    print('DOF = ', welch_dof(f_g1, f_g2))\n",
    "    \n",
    "    t, p = stats.ttest_ind(f_g1, f_g2, equal_var=False)\n",
    "    \n",
    "    tabulated_data['feature'].append(feature_label)\n",
    "    tabulated_data['NGB mean (SEM)'].append(f'{np.mean(f_g1):.3g} ({np.std(f_g1)/len(f_g1)**0.5:.3g})')\n",
    "    tabulated_data['SB mean (SEM)'].append(f'{np.mean(f_g2):.3g} ({np.std(f_g2)/len(f_g2)**0.5:.3g})')\n",
    "    tabulated_data['df'].append(f'{welch_dof(f_g1, f_g2):.3g}')\n",
    "    tabulated_data['Welch’s t'].append(f'{t:.3g}')\n",
    "    tabulated_data['p'].append(f'{p:.3g}')\n",
    "    tabulated_data['Cohen’s d'].append(f'{cohen_d_for_welch(f_g1, f_g2):.3g}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(tabulated_data).set_index('feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burst group spike statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_isi_g1 = np.array([len(burst.spikes)/burst.feature_vec[0] for burst in striatum_ngb if len(burst.spikes)>1])\n",
    "spike_isi_g2 = np.array([len(burst.spikes)/burst.feature_vec[0] for burst in striatum_sb if len(burst.spikes)>1])\n",
    "\n",
    "log_spike_isi_g1 = spike_isi_g1\n",
    "log_spike_isi_g2 = spike_isi_g2\n",
    "\n",
    "print('NGB median', np.nanmedian(spike_isi_g1))\n",
    "print('SB median', np.nanmedian(spike_isi_g2))\n",
    "\n",
    "print('Spikes ISI:', stats.mannwhitneyu(spike_isi_g1, spike_isi_g2))\n",
    "\n",
    "bins = 10**np.arange(-1, 2+0.1, 0.1)\n",
    "weights = [np.ones(len(log_spike_isi_g1)) / float(len(log_spike_isi_g1)), np.ones(len(log_spike_isi_g2)) / float(len(log_spike_isi_g2))]\n",
    "plt.hist(\n",
    "    [log_spike_isi_g1],\n",
    "    label=['NGB'],\n",
    "    color=['tab:blue'],\n",
    "    weights=weights[0],\n",
    "    bins=np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins)),\n",
    "    alpha=0.75\n",
    ");\n",
    "plt.hist(\n",
    "    [log_spike_isi_g2],\n",
    "    label=['SB'],\n",
    "    color=['tab:red'],\n",
    "    weights=weights[1],\n",
    "    bins=np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins)),\n",
    "    alpha=0.75\n",
    ");\n",
    "plt.legend()\n",
    "plt.xlabel(feature_label)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Log spike rate (Hz)')\n",
    "plt.ylim(0,0.25)\n",
    "plt.xlim(10**-1, 10**2)\n",
    "format_plot(plt.gca(), legend=False, size=[17.5, 20])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spike_n_g1 = np.array([len(burst.spikes) for burst in striatum_ngb])\n",
    "spike_n_g2 = np.array([len(burst.spikes) for burst in striatum_sb])\n",
    "\n",
    "log_spike_n_g1 = spike_n_g1[np.nonzero(spike_n_g1)]\n",
    "log_spike_n_g2 = spike_n_g2[np.nonzero(spike_n_g2)]\n",
    "\n",
    "zero_spike_n_g1 = len([0 for burst in bursts_g1 if not len(burst.spikes)])\n",
    "zero_spike_n_g2 = len([0 for burst in bursts_g2 if not len(burst.spikes)])\n",
    "\n",
    "print('NGB median', np.median(spike_n_g1))\n",
    "print('SB median', np.median(spike_n_g2))\n",
    "\n",
    "print('NGB non-zero median', np.median(spike_n_g1[np.nonzero(spike_n_g1)]))\n",
    "print('SB non-zero median', np.median(spike_n_g2[np.nonzero(spike_n_g2)]))\n",
    "print('Spikes count:', stats.mannwhitneyu(spike_n_g1[np.nonzero(spike_n_g1)], spike_n_g2[np.nonzero(spike_n_g2)]))\n",
    "\n",
    "g1_pc = zero_spike_n_g1/len(spike_n_g1)*100\n",
    "g2_pc = zero_spike_n_g2/len(spike_n_g2)*100\n",
    "\n",
    "print('G1 zero percent', g1_pc)\n",
    "print('G2 zero percent', g2_pc)\n",
    "\n",
    "fig = plt.figure(figsize=[3,4])\n",
    "plt.bar([0, 1], [g1_pc, g2_pc], color=['tab:blue', 'tab:red'])\n",
    "plt.xticks([0, 1], ['NGB', 'SB'])\n",
    "plt.ylabel('% events with 0 spikes')\n",
    "plt.ylim(0,50)\n",
    "format_plot(plt.gca(), legend=False, size=[17.5, 20])\n",
    "plt.show()\n",
    "\n",
    "bins = 10**np.arange(0, 3+0.25, 0.25)\n",
    "weights = [np.ones(len(log_spike_n_g1)) / float(len(log_spike_n_g1)), np.ones(len(log_spike_n_g2)) / float(len(log_spike_n_g2))]\n",
    "plt.hist(\n",
    "    [log_spike_n_g1],\n",
    "    label=['NGB'],\n",
    "    color=['tab:blue'],\n",
    "    weights=weights[0],\n",
    "    bins=np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins)),\n",
    "    alpha=0.75\n",
    ");\n",
    "plt.hist(\n",
    "    [log_spike_n_g2],\n",
    "    label=['SB'],\n",
    "    color=['tab:red'],\n",
    "    weights=weights[1],\n",
    "    bins=np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins)),\n",
    "    alpha=0.75\n",
    ");\n",
    "plt.legend()\n",
    "plt.xlabel(feature_label)\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel('Log spikes per event')\n",
    "plt.ylim(0,0.5)\n",
    "plt.xlim(10**0, 10**3.0)\n",
    "plt.xscale('log')\n",
    "format_plot(plt.gca(), legend=True, size=[17.5, 20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha-beta power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_beta (bursts):\n",
    "    alpha = []\n",
    "    beta = []\n",
    "    for burst in bursts:\n",
    "        if hasattr(burst, \"normalized_psd\"):\n",
    "            f_burst, Pxx_burst = burst.normalized_psd\n",
    "\n",
    "            _, Pxx_alpha = get_psd_in_range((f_burst, Pxx_burst), [4, 12])\n",
    "            _, Pxx_beta = get_psd_in_range((f_burst, Pxx_burst), [12, 20])\n",
    "\n",
    "            alpha.append(np.mean(Pxx_alpha))\n",
    "            beta.append(np.mean(Pxx_beta))\n",
    "            \n",
    "    return alpha, beta\n",
    " \n",
    "alpha_mns = []\n",
    "alpha_errs = []\n",
    "\n",
    "beta_mns = []\n",
    "beta_errs = []\n",
    "    \n",
    "for key, group in zip(['thal', 'cp', 'ctx'], [cortex_ngb, striatum_ngb, thalamus_ngb]):\n",
    "    print(f'\\n{key}')\n",
    "    \n",
    "    alpha, beta = get_alpha_beta(group)\n",
    "    \n",
    "    alpha_mns.append(np.mean(alpha))\n",
    "    alpha_errs.append(np.std(alpha)/len(alpha)**0.5)\n",
    "    beta_mns.append(np.mean(beta))\n",
    "    beta_errs.append(np.std(beta)/len(beta)**0.5)\n",
    "\n",
    "    print('Mean alpha-theta =', np.mean(alpha), 'low-beta =', np.mean(beta))\n",
    "    print('Std alpha-theta =', np.std(alpha), 'low-beta =', np.std(beta))\n",
    "    print(stats.ttest_ind(alpha, beta, equal_var=False))\n",
    "    print('Cohen\\'s d =', cohen_d_for_welch(alpha, beta))\n",
    "    print('DOF = ', welch_dof(alpha, beta))\n",
    "\n",
    "x = np.arange(3)\n",
    "plt.bar(x-0.125, alpha_mns, yerr=alpha_errs, width=0.25, label='4-12 Hz')\n",
    "plt.bar(x+0.125, beta_mns, yerr=beta_errs, width=0.25, label='12-20 Hz')\n",
    "plt.xticks(x, ['Cortex', 'Striatum', 'Thalamus'])\n",
    "plt.legend()\n",
    "format_plot(plt.gca(), legend=True, size=[17.5, 20])\n",
    "plt.ylabel('Mean relative power ($P/P_{0}$)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "diffs_arr = []\n",
    "for key, group in zip(['thal', 'cp', 'ctx'], [cortex_ngb, striatum_ngb, thalamus_ngb]):\n",
    "    alpha, beta = get_alpha_beta(group)\n",
    "    \n",
    "    diff = np.array(alpha)-np.array(beta)\n",
    "    diffs_arr.append(diff)\n",
    "\n",
    "ctx_diff, cp_diff, thal_diff  = diffs_arr\n",
    "\n",
    "for pair_name, pair in zip(['ctx-cp', 'ctx-thal', 'thal-cp'], [(ctx_diff, cp_diff), (ctx_diff, thal_diff), (thal_diff, cp_diff)]):\n",
    "    print(f'\\n{pair_name}')\n",
    "    \n",
    "    a_diff, b_diff = pair\n",
    "\n",
    "    print('Mean alpha-theta =', np.mean(a_diff), 'low-beta =', np.mean(b_diff))\n",
    "    print('Std alpha-theta =', np.std(a_diff), 'low-beta =', np.std(b_diff))\n",
    "    print(stats.ttest_ind(a_diff, b_diff, equal_var=False)[0], stats.ttest_ind(a_diff, b_diff, equal_var=False)[1]*3)\n",
    "    print('Cohen\\'s d =', cohen_d_for_welch(a_diff, b_diff))\n",
    "    print('DOF = ', welch_dof(a_diff, b_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=[20,10])\n",
    "axs = axs.reshape(-1)\n",
    "    \n",
    "for feature_idx, feature_label in enumerate(feature_vector_labels_full):\n",
    "    striatum_g1 = [f[feature_idx] for f in cortex_ngb_features]\n",
    "    thal_g1     = [f[feature_idx] for f in thalamus_ngb_features]\n",
    "    \n",
    "    weights = [np.ones(len(striatum_g1)) / float(len(striatum_g1)), np.ones(len(thal_g1)) / float(len(thal_g1))]\n",
    "    \n",
    "    axs[feature_idx].hist([striatum_g1, thal_g1], label=['Cortex', 'CL/Pf'], weights=weights, color=[COLOR_CORTEX, COLOR_STRIATUM])\n",
    "    axs[feature_idx].set_xlabel(feature_label)\n",
    "    axs[feature_idx].set_ylabel('Density')\n",
    "    axs[feature_idx].set_ylim([0, 1])\n",
    "    \n",
    "    format_plot(axs[feature_idx], legend=False, size=[17.5, 20])\n",
    "    \n",
    "    print('\\n', '', feature_label)\n",
    "    print(np.mean(striatum_g1), np.mean(thal_g1))\n",
    "    print(np.std(striatum_g1), np.std(thal_g1))\n",
    "    print(stats.ttest_ind(striatum_g1, thal_g1, equal_var=False))\n",
    "    print('Cohen\\'s d =', cohen_d_for_welch(striatum_g1, thal_g1))\n",
    "    print('DOF = ', welch_dof(striatum_g1, thal_g1))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-ratio between burst groups and regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://onlinelibrary.wiley.com/doi/epdf/10.1111/j.1442-9993.2001.01070.pp.x\n",
    "\n",
    "def multivariate_f_ratio (a, b):\n",
    "    a_group_means = np.mean(a, axis=0)\n",
    "    b_group_means = np.mean(b, axis=0)\n",
    "    overall_means = np.mean(np.concatenate([a,b]), axis=0)\n",
    "\n",
    "    ss_between_group = 0\n",
    "    ss_between_group += (len(a) * np.linalg.norm(overall_means-a_group_means)**2)\n",
    "    ss_between_group += (len(b) * np.linalg.norm(overall_means-b_group_means)**2)\n",
    "    \n",
    "    ss_within_group = 0\n",
    "    for feature_vec in a:\n",
    "        ss_within_group += (np.linalg.norm(a_group_means-feature_vec)**2)\n",
    "    for feature_vec in b:\n",
    "        ss_within_group += (np.linalg.norm(b_group_means-feature_vec)**2)      \n",
    "    ss_within_group = ss_within_group / (len(a)+len(b) - 2)\n",
    "  \n",
    "    f = ss_between_group/ss_within_group\n",
    "    return f\n",
    "\n",
    "def permute_multivariate_f_ratio (a, b, iterations):\n",
    "    combined = np.concatenate([a, b])\n",
    "\n",
    "    test_stat = multivariate_f_ratio(a, b)\n",
    "    null_dist = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        shuffled = np.random.permutation(combined)\n",
    "        a_shuffled = shuffled[:len(a)]\n",
    "        b_shuffled = shuffled[len(a):]\n",
    "\n",
    "        f = multivariate_f_ratio(a_shuffled, b_shuffled)\n",
    "        null_dist.append(f)\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('Iteration', i+1)\n",
    "\n",
    "    p_val = len(np.where(null_dist>= test_stat)[0]) / len(null_dist)\n",
    "    \n",
    "    return p_val, test_stat, null_dist\n",
    "    \n",
    "p, f, null = permute_multivariate_f_ratio(striatum_ngb_features, striatum_sb_features, iterations=1000)\n",
    "\n",
    "bins = 100\n",
    "max_val = np.max(np.histogram(null, bins=bins)[0])\n",
    "\n",
    "\n",
    "plt.hist(null, bins=bins, facecolor='dimgray')\n",
    "plt.plot([f, f], [0, max_val])\n",
    "plt.xlabel('F-value')\n",
    "plt.ylabel('Count')\n",
    "format_plot(plt.gca(), legend=False)\n",
    "plt.show()\n",
    "\n",
    "print('p = {}, F({}, {}) = {}'.format(\n",
    "    p,\n",
    "    1,\n",
    "    len(striatum_ngb_features) + len(striatum_sb_features) - 2,\n",
    "    f\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 100\n",
    "max_val = np.max(np.histogram(null, bins=bins)[0])\n",
    "\n",
    "fig, (ax,ax2) = plt.subplots(1, 2, sharey=True, facecolor='w')\n",
    "\n",
    "# plot the same data on both axes\n",
    "ax.hist(null, bins=bins, facecolor='dimgray')\n",
    "ax2.plot([f, f], [0, max_val-1000], c='tab:orange')\n",
    "\n",
    "ax.set_xlim(0,14.5)\n",
    "ax2.set_xlim(8509-7.25, 8509+7.25)\n",
    "ax.set_ylim(0, 1500)\n",
    "\n",
    "ax.set_xlabel('F-value')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax.yaxis.tick_left()\n",
    "ax.tick_params(labelright='off')\n",
    "ax2.yaxis.tick_right()\n",
    "\n",
    "format_plot(ax, legend=False)\n",
    "format_plot(ax2, legend=False)\n",
    "\n",
    "d = .015 \n",
    "kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
    "ax.plot((1-d,1+d), (-d,+d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes) \n",
    "ax2.plot((-d,+d), (-d,+d), **kwargs)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bursts over time in different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_group_lineplots (data, ylim, labels, xticks, colors=['blue', 'orange'], title='', xlabel='', ylabel='', yscale='linear', save=False):    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    lines = []\n",
    "    for idx, data_group in enumerate(data):\n",
    "        shift = None\n",
    "        \n",
    "        if len(data) == 1:\n",
    "            shift = 0\n",
    "        elif len(data) == 2 and idx == 0:\n",
    "            shift = -0.4\n",
    "        elif len(data) ==2 and idx == 1:\n",
    "            shift = 0.4\n",
    "\n",
    "        positions = np.array(range(len(data_group)))# * 2 + shift\n",
    "        line = plt.errorbar(\n",
    "            positions,\n",
    "            [np.mean(group) for group in data_group],\n",
    "            yerr=[np.std(group)/(len(data_group)**0.5) for group in data_group],\n",
    "            capsize=5,\n",
    "            c=colors[idx]\n",
    "        )\n",
    "        \n",
    "        for group_idx, group in enumerate(data_group):\n",
    "            xpos = [positions[group_idx] for i in range(len(group))]\n",
    "            plt.plot(xpos, group, c=colors[idx], lw=0, marker='o', alpha=0.25)\n",
    "        \n",
    "        lines.append(line)\n",
    "        \n",
    "    plt.xticks(np.arange(len(xticks)), xticks)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.yscale(yscale)\n",
    "    plt.ylim(ylim)\n",
    "        \n",
    "    leg = plt.legend([line for line in lines], labels, frameon=False, fontsize=15, bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(2.0)\n",
    "        \n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    for item in ([ax.title] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(12.5)\n",
    "    for item in ([ax.xaxis.label, ax.yaxis.label] + ax.get_legend().get_texts()):\n",
    "        item.set_fontsize(15)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(FIG_ROOT + save, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# GROUP is group of bursts identified earlier via PCA\n",
    "# set to bursts_g1/bursts_g2\n",
    "GROUP = {\n",
    "    \"NGB\": cortex_ngb,\n",
    "    \"SB\": cortex_sb\n",
    "}\n",
    "    \n",
    "occurence = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "occurence_csv = {\n",
    "    \"burst_type\": [],\n",
    "    \"age\": [],\n",
    "    \"path\": [],\n",
    "    \"bursts_per_second\": []\n",
    "}\n",
    "\n",
    "amplitude = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "amplitude_csv = {\n",
    "    \"burst_type\": [],\n",
    "    \"age\": [],\n",
    "    \"path\": [],\n",
    "    \"amplitude\": []\n",
    "}\n",
    "\n",
    "duration = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "duration_csv = {\n",
    "    \"burst_type\": [],\n",
    "    \"age\": [],\n",
    "    \"path\": [],\n",
    "    \"duration\": []\n",
    "}\n",
    "\n",
    "spike_rate = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "spike_rate_csv = {\n",
    "    \"burst_type\": [],\n",
    "    \"age\": [],\n",
    "    \"path\": [],\n",
    "    \"spike_rate\": []\n",
    "}\n",
    "\n",
    "alphatheta_power = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "betagamma_power = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "alphatheta_peak = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "betagamma_peak = {\n",
    "    \"NGB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"SB\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "box_labels = [\"NGB\", \"SB\"]\n",
    "age_group_labels = list(occurence[\"SB\"].keys())\n",
    "\n",
    "for brain_area in [\"cortex\"]:\n",
    "    brain_area_bursts = brain_area + \"_bursts\"\n",
    "    \n",
    "    for recording_n, recording in enumerate(rms_processed_recordings):\n",
    "        if not brain_area_bursts in recording:\n",
    "            continue\n",
    "            \n",
    "        print(\"Processing {}, recording {}/{}\".format(brain_area, recording_n+1, len(rms_processed_recordings)))\n",
    "\n",
    "        age = recording[\"age\"]    \n",
    "        if age < 7:\n",
    "            age_group = \"5-6\"\n",
    "        elif age >= 7 and age < 9:\n",
    "            age_group = \"7-8\"\n",
    "        elif age >= 9 and age < 11:\n",
    "            age_group = \"9-10\"\n",
    "        elif age >= 11 and age < 13:\n",
    "            age_group = \"11-12\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        total_bursts_ngb = []\n",
    "        total_bursts_sb = []\n",
    "        \n",
    "        amplitude_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        duration_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        spike_rate_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        alphatheta_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        betagamma_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        alphatheta_peak_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        betagamma_peak_recording = {\n",
    "            \"NGB\": [],\n",
    "            \"SB\": []\n",
    "        }\n",
    "        \n",
    "        for burst_idx, burst in enumerate(recording[brain_area_bursts]):            \n",
    "            if (burst in GROUP['SB']):\n",
    "                group_key = 'SB'\n",
    "                total_bursts_sb.append(burst)\n",
    "            elif burst in GROUP['NGB']:\n",
    "                group_key = 'NGB'\n",
    "                total_bursts_ngb.append(burst)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            amplitude_recording[group_key].append(np.max(burst.data)-np.min(burst.data))\n",
    "            duration_recording[group_key].append((burst.time[1] - burst.time[0])/SAMPLING_RATE)\n",
    "            spike_rate_recording[group_key].append(burst.feature_vec[8])\n",
    "            alphatheta_recording[group_key].append(burst.feature_vec[6])\n",
    "            betagamma_recording[group_key].append(burst.feature_vec[5])\n",
    "            \n",
    "            f, Pxx = burst.normalized_psd\n",
    "\n",
    "            theta_idx = np.where(f >= 4)[0][0] \n",
    "            beta_idx = np.where(f >= 16)[0][0]\n",
    "            lgamma_idx = np.where(f >= 40)[0][0]\n",
    "\n",
    "            alphatheta_peak_ = f[np.argmax(Pxx[theta_idx:beta_idx])+theta_idx]\n",
    "            betagamma_peak_ = f[np.argmax(Pxx[beta_idx:lgamma_idx])+beta_idx]\n",
    "\n",
    "            alphatheta_peak_recording[group_key].append(alphatheta_peak_)\n",
    "            betagamma_peak_recording[group_key].append(betagamma_peak_)\n",
    "            \n",
    "        occurence_ngb = len(total_bursts_ngb) / (recording[\"length\"] / SAMPLING_RATE) * 60\n",
    "        occurence_sb = len(total_bursts_sb) / (recording[\"length\"] / SAMPLING_RATE) * 60\n",
    "        \n",
    "        occurence[\"NGB\"][age_group].append(occurence_ngb)\n",
    "        occurence_csv[\"burst_type\"].append('ngb')\n",
    "        occurence_csv[\"age\"].append(recording[\"age\"])\n",
    "        occurence_csv[\"path\"].append(recording[\"path\"])\n",
    "        occurence_csv[\"bursts_per_second\"].append(occurence_ngb)\n",
    "        \n",
    "        occurence[\"SB\"][age_group].append(occurence_sb)\n",
    "        occurence_csv[\"burst_type\"].append('sb')\n",
    "        occurence_csv[\"age\"].append(recording[\"age\"])\n",
    "        occurence_csv[\"path\"].append(recording[\"path\"])\n",
    "        occurence_csv[\"bursts_per_second\"].append(occurence_sb)\n",
    "        \n",
    "        if len(amplitude_recording[\"NGB\"]):\n",
    "            amplitude[\"NGB\"][age_group].append(np.mean(amplitude_recording[\"NGB\"]))\n",
    "            \n",
    "            amplitude_csv[\"burst_type\"].append('ngb')\n",
    "            amplitude_csv[\"age\"].append(recording[\"age\"])\n",
    "            amplitude_csv[\"path\"].append(recording[\"path\"])\n",
    "            amplitude_csv[\"amplitude\"].append(np.mean(amplitude_recording[\"NGB\"]))\n",
    "        if len(amplitude_recording[\"SB\"]):\n",
    "            amplitude[\"SB\"][age_group].append(np.nanmean(amplitude_recording[\"SB\"]))\n",
    "        \n",
    "            amplitude_csv[\"burst_type\"].append('sb')\n",
    "            amplitude_csv[\"age\"].append(recording[\"age\"])\n",
    "            amplitude_csv[\"path\"].append(recording[\"path\"])\n",
    "            amplitude_csv[\"amplitude\"].append(np.mean(amplitude_recording[\"SB\"]))\n",
    "            \n",
    "        if len(duration_recording[\"NGB\"]):\n",
    "            duration[\"NGB\"][age_group].append(np.mean(duration_recording[\"NGB\"]))\n",
    "            \n",
    "            duration_csv[\"burst_type\"].append('ngb')\n",
    "            duration_csv[\"age\"].append(recording[\"age\"])\n",
    "            duration_csv[\"path\"].append(recording[\"path\"])\n",
    "            duration_csv[\"duration\"].append(np.mean(duration_recording[\"NGB\"]))\n",
    "        if len(duration_recording[\"SB\"]):\n",
    "            duration[\"SB\"][age_group].append(np.nanmean(duration_recording[\"SB\"]))\n",
    "                        \n",
    "            duration_csv[\"burst_type\"].append('sb')\n",
    "            duration_csv[\"age\"].append(recording[\"age\"])\n",
    "            duration_csv[\"path\"].append(recording[\"path\"])\n",
    "            duration_csv[\"duration\"].append(np.mean(duration_recording[\"SB\"]))\n",
    "            \n",
    "        if len(spike_rate_recording[\"NGB\"]):\n",
    "            spike_rate[\"NGB\"][age_group].append(np.mean(spike_rate_recording[\"NGB\"]))\n",
    "            \n",
    "            spike_rate_csv[\"burst_type\"].append('ngb')\n",
    "            spike_rate_csv[\"age\"].append(recording[\"age\"])\n",
    "            spike_rate_csv[\"path\"].append(recording[\"path\"])\n",
    "            spike_rate_csv[\"spike_rate\"].append(np.mean(spike_rate_recording[\"NGB\"]))\n",
    "        if len(spike_rate_recording[\"SB\"]):\n",
    "            spike_rate[\"SB\"][age_group].append(np.mean(spike_rate_recording[\"SB\"]))\n",
    "            \n",
    "            spike_rate_csv[\"burst_type\"].append('sb')\n",
    "            spike_rate_csv[\"age\"].append(recording[\"age\"])\n",
    "            spike_rate_csv[\"path\"].append(recording[\"path\"])\n",
    "            spike_rate_csv[\"spike_rate\"].append(np.mean(spike_rate_recording[\"SB\"]))\n",
    "        \n",
    "        if len(alphatheta_recording[\"NGB\"]):\n",
    "            alphatheta_power[\"NGB\"][age_group].append(np.mean(alphatheta_recording[\"NGB\"]))\n",
    "        if len(alphatheta_recording[\"SB\"]):\n",
    "            alphatheta_power[\"SB\"][age_group].append(np.mean(alphatheta_recording[\"SB\"]))\n",
    "        \n",
    "        if len(betagamma_recording[\"NGB\"]):\n",
    "            betagamma_power[\"NGB\"][age_group].append(np.mean(betagamma_recording[\"NGB\"]))\n",
    "        if len(betagamma_recording[\"SB\"]):\n",
    "            betagamma_power[\"SB\"][age_group].append(np.mean(betagamma_recording[\"SB\"]))\n",
    "        \n",
    "        if len(alphatheta_peak_recording[\"NGB\"]):\n",
    "            alphatheta_peak[\"NGB\"][age_group].append(np.mean(alphatheta_peak_recording[\"NGB\"]))\n",
    "        if len(alphatheta_peak_recording[\"SB\"]):\n",
    "            alphatheta_peak[\"SB\"][age_group].append(np.mean(alphatheta_peak_recording[\"SB\"]))\n",
    "        \n",
    "        if len(betagamma_peak_recording[\"NGB\"]):\n",
    "            betagamma_peak[\"NGB\"][age_group].append(np.mean(betagamma_peak_recording[\"NGB\"]))\n",
    "        if len(betagamma_peak_recording[\"SB\"]):\n",
    "            betagamma_peak[\"SB\"][age_group].append(np.mean(betagamma_peak_recording[\"SB\"]))\n",
    "        \n",
    "\n",
    "# Parameters to pass to boxplot function\n",
    "plot_parameters = [\n",
    "    { \"title\": \"occurence\", \"ylabel\": \"Bursts $\\mathregular{s^{-1}}$\", \"data\": occurence, \"ylim\": [None, None] },\n",
    "    { \"title\": \"amplitude\", \"ylabel\": \"Amplitude (μV)\", \"data\": amplitude, \"ylim\": [200, 2000] },\n",
    "    { \"title\": \"duration\", \"ylabel\": \"Duration (s)\", \"data\": duration, \"ylim\": [0, 10] },\n",
    "    { \"title\": \"alphatheta\", \"ylabel\": \"Relative alpha-theta power\", \"data\": alphatheta_power, \"ylim\": [0, 0.6] },\n",
    "    { \"title\": \"alphatheta_peak\", \"ylabel\": \"Peak alpha-theta frequency\", \"data\": alphatheta_peak, \"ylim\": [5, 15] },\n",
    "    { \"title\": \"betagamma\", \"ylabel\": \"Relative beta-gamma power\", \"data\": betagamma_power, \"ylim\": [0.25, 0.65] },\n",
    "    { \"title\": \"betagamma_peak\", \"ylabel\": \"Peak beta-gamma frequency\", \"data\": betagamma_peak, \"ylim\": [15, 30] }\n",
    "]\n",
    "\n",
    "tabulated_data = {\n",
    "    'feature': [],\n",
    "    'NGB mean (σ) P5-6': [],\n",
    "    'SB mean (σ) P5-6': [],\n",
    "    'NGB mean (σ) P7-8': [],\n",
    "    'SB mean (σ) P7-8': [],\n",
    "    'NGB mean (σ) P9-10': [],\n",
    "    'SB mean (σ) P9-10': [],\n",
    "    'NGB mean (σ) P11-12': [],\n",
    "    'SB mean (σ) P11-12': []\n",
    "}\n",
    "\n",
    "# Box plots\n",
    "for plot_param in plot_parameters:\n",
    "    data = plot_param[\"data\"]\n",
    "    age_groups_data = []\n",
    "        \n",
    "    tabulated_data['feature'].append(plot_param['title'])\n",
    "        \n",
    "    for brain_area_values in zip(data.keys(), data.values()):\n",
    "        brain_key, brain_area = brain_area_values\n",
    "        print('\\t', brain_key)\n",
    "        \n",
    "        temp_mn = []\n",
    "        temp_std = []\n",
    "        \n",
    "        age_groups = []\n",
    "        for age_group_values in zip(brain_area.keys(), brain_area.values()):\n",
    "            age_group_key, age_group = age_group_values\n",
    "            \n",
    "            tab_key = f'{brain_key} mean (σ) P{age_group_key}'\n",
    "            tabulated_data[tab_key].append(\n",
    "                f'{round(np.mean(age_group), 1)} ({round(np.std(age_group)/len(age_group)**0.5, 2)})'\n",
    "            )\n",
    "            \n",
    "            age_groups.append(age_group)\n",
    "            \n",
    "            temp_mn.append(np.mean(age_group))\n",
    "            temp_std.append(np.std(age_group))\n",
    "        \n",
    "        print(np.mean(temp_mn), np.mean(temp_std))\n",
    "        age_groups_data.append(age_groups)\n",
    "\n",
    "    plot_group_lineplots(\n",
    "        data=age_groups_data,\n",
    "        ylim=plot_param[\"ylim\"],\n",
    "        labels=box_labels,\n",
    "        xticks=age_group_labels,\n",
    "        colors=['tab:blue', 'tab:red'],\n",
    "        xlabel=\"Age (days)\",\n",
    "        ylabel=plot_param[\"ylabel\"],\n",
    "        yscale=('log' if plot_param[\"title\"] == \"Duration\" or plot_param[\"title\"] == \"Amplitude\" else 'linear')\n",
    "    )\n",
    "    \n",
    "    print(twoway_anova(data, ['burst_type', 'age', 'value']))\n",
    "    \n",
    "display(pd.DataFrame(tabulated_data).set_index('feature'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk]",
   "language": "python",
   "name": "conda-env-allensdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
