{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "from scipy import ndimage\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utilities import *\n",
    "from detect_mua import detect_MUA, get_spike_wave_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of dicts for recording data in format:\n",
    "RECORDINGS = [\n",
    "    {\n",
    "        \"path\": \"\",           # Path to recording (folder name)\n",
    "        \"age\": ,              # Age of animal at recording\n",
    "        \"thalamus\": ,         # Does recording have thalamus probe?\n",
    "        \"striatum_channel\": , # Striatum channel to use\n",
    "        \"cortex_channel\": ,   # Cortex channel to use\n",
    "        \"recording\": ,        # Recording within folder\n",
    "        \"striatum_sigma\": ,   # Sigma threshold (for altenative burst detection method)\n",
    "        \"cortex_sigma\":       # Sigma threshold (for altenative burst detection method)\n",
    "    }\n",
    "]\n",
    "\n",
    "RECORDINGS = sorted(RECORDINGS, key=lambda k: k['age']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open previously saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_processed_recordings = open_data('') # Path to processed data (pickle file format)\n",
    "processed_recordings_mua = open_data('') # Path to processed data (pickle file format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burst detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect_bursts_from_envelope(envelope, low_threshold):\n",
    "    bursts = []\n",
    "    \n",
    "    start_t = False\n",
    "    burst = []\n",
    "    \n",
    "    for t, sample in enumerate(envelope):\n",
    "        if sample > low_threshold:\n",
    "            if not start_t:\n",
    "                start_t = t\n",
    "            burst.append(sample)\n",
    "            \n",
    "        if start_t and (sample <= low_threshold or t+1 == len(envelope)):\n",
    "            bursts.append( Burst([start_t, t], burst) )\n",
    "            start_t = False\n",
    "            burst = []\n",
    "    \n",
    "    return bursts\n",
    "        \n",
    "\n",
    "# Filter bursts shorter than minimum duration\n",
    "def filter_short_bursts (bursts, minimum_duration):\n",
    "    filtered_bursts = []\n",
    "    \n",
    "    for burst in bursts:\n",
    "        if (burst.time[1] - burst.time[0]) > (minimum_duration*SAMPLING_RATE):\n",
    "            filtered_bursts.append(burst)\n",
    "            \n",
    "    return filtered_bursts\n",
    "\n",
    "# Filter bursts that have fewer than minimum points above threshold\n",
    "def filter_minimum_peaks (bursts, threshold, minimum_peaks):\n",
    "    filtered_bursts = []\n",
    "    \n",
    "    for burst in bursts:\n",
    "        peaks = signal.find_peaks(np.abs(burst.data), prominence=threshold)[0]\n",
    "        diff_count = 0\n",
    "        \n",
    "        for peak_idx, peak in enumerate(peaks):\n",
    "            if peak_idx+1 == len(peaks):\n",
    "                continue\n",
    "                \n",
    "            next_peak = peaks[peak_idx+1]\n",
    "            diff = (next_peak - peak)/SAMPLING_RATE\n",
    "\n",
    "            if diff_count == (minimum_peaks-1):\n",
    "                break\n",
    "            \n",
    "            if diff < 0.2:\n",
    "                diff_count += 1\n",
    "            else:\n",
    "                diff = 0\n",
    "                \n",
    "        \n",
    "        if diff_count == minimum_peaks-1:\n",
    "            filtered_bursts.append(burst)\n",
    "            \n",
    "    return filtered_bursts\n",
    "\n",
    "# If bursts have been bandpass filtered, use this function\n",
    "# to return unfiltered bursts using saved time points for each burst\n",
    "def get_unfiltered_bursts (bursts, data):\n",
    "    unfiltered_bursts = []\n",
    "    \n",
    "    for burst in bursts:\n",
    "        burst_slice = slice(*burst.time)\n",
    "        unfiltered_bursts.append( Burst(burst.time, data[burst_slice]) )\n",
    "\n",
    "    return unfiltered_bursts\n",
    "\n",
    "def get_baseline_periods (bursts, data):\n",
    "    baseline_bursts = []\n",
    "    \n",
    "    padding = int(SAMPLING_RATE * 0.5) # 0.1 seconds\n",
    "    \n",
    "    for idx, burst in enumerate(bursts):\n",
    "        # If on final burst of set\n",
    "        if (idx+1) == len(bursts):\n",
    "            continue\n",
    "            \n",
    "        next_burst_time = bursts[idx+1][0]\n",
    "        curr_burst_time = burst[0]\n",
    "        time_diff = next_burst_time[0] - curr_burst_time[1]\n",
    "\n",
    "        if time_diff > (padding*4):\n",
    "            start_t = next_burst_time[0] + padding\n",
    "            end_t = curr_burst_time[1] - padding\n",
    "            baseline_data = data[start_t:end_t]\n",
    "            baseline_bursts.append( ([start_t, end_t], baseline_data) )\n",
    "\n",
    "    return baseline_bursts\n",
    "\n",
    "def combined_adjacent_bursts(bursts, data, temporal_distance):\n",
    "    combined_bursts = []\n",
    "    temp_bursts = []\n",
    "    \n",
    "    # Take first and last bursts and combine\n",
    "    def combine_bursts (temp_bursts):\n",
    "        start = temp_bursts[0].time[0]\n",
    "        end = temp_bursts[-1].time[1]\n",
    "        \n",
    "        return Burst([start, end], data[start:end])\n",
    "    \n",
    "    for burst_idx, burst in enumerate(bursts):    \n",
    "        if burst_idx == 0:\n",
    "            continue\n",
    "            \n",
    "        prev = bursts[burst_idx-1]\n",
    "        \n",
    "        prev_time = prev.time\n",
    "        curr_time = burst.time\n",
    "        \n",
    "        temp_bursts.append(prev)\n",
    "        \n",
    "        # If bursts are greater than 1 second apart\n",
    "        if (curr_time[0] - prev_time[1] > temporal_distance*SAMPLING_RATE):\n",
    "            combined_bursts.append(combine_bursts(temp_bursts))\n",
    "            temp_bursts = []\n",
    "        \n",
    "        # Or if on final burst of set\n",
    "        if burst_idx+1 == len(bursts):\n",
    "            temp_bursts.append(burst)\n",
    "            \n",
    "            combined_bursts.append(combine_bursts(temp_bursts))\n",
    "            temp_bursts = []\n",
    "            \n",
    "    return combined_bursts\n",
    "\n",
    "\n",
    "def hl_envelopes_idx(s, dmin=1, dmax=1):\n",
    "    # locals min      \n",
    "    lmin = (np.diff(np.sign(np.diff(s))) > 0).nonzero()[0] + 1 \n",
    "    # locals max\n",
    "    lmax = (np.diff(np.sign(np.diff(s))) < 0).nonzero()[0] + 1 \n",
    "\n",
    "\n",
    "    # global max of dmax-chunks of locals max \n",
    "    lmin = lmin[[i+np.argmin(s[lmin[i:i+dmin]]) for i in range(0,len(lmin),dmin)]]\n",
    "    # global min of dmin-chunks of locals min \n",
    "    lmax = lmax[[i+np.argmax(s[lmax[i:i+dmax]]) for i in range(0,len(lmax),dmax)]]\n",
    "    \n",
    "    return lmin,lmax\n",
    "            \n",
    "\n",
    "# Cobmines all previous functions into a single routine\n",
    "# Returns list of burst tuples in form ([start time, end time], [burst data])\n",
    "\n",
    "# Samples              Array of sampled data\n",
    "# Sigma                How many standard deviations above mean for threshold\n",
    "# Minimum_duration     Minimum burst duration to keep\n",
    "\n",
    "def run_burst_procedure (data, minimum_peaks, minimum_duration, sigma):\n",
    "    # Bandpass filter signal\n",
    "    data_bandpass = butter_bandpass_filter(data, lowcut=1, highcut=100)\n",
    "        \n",
    "    # Get envelope of signal\n",
    "    low_idx, high_idx = hl_envelopes_idx(data_bandpass, dmin=30, dmax=30)\n",
    "    x = np.arange(0, len(data_bandpass))\n",
    "    high_env = np.interp(x, x[high_idx], data_bandpass[high_idx])\n",
    "    low_env = np.interp(x, x[low_idx], data_bandpass[low_idx])\n",
    "    mean_env = []\n",
    "    for t, _ in enumerate(high_env):\n",
    "        a, b = high_env[t], abs(low_env[t])\n",
    "        if a > b:\n",
    "            mean_env.append(a)\n",
    "        else:\n",
    "            mean_env.append(b)\n",
    "    \n",
    "    # Clip data to prevent skew of std from random outlier events\n",
    "    data_clipped = np.clip(data_bandpass, a_min=-1000, a_max=1000)\n",
    "    \n",
    "    # Get thresholds\n",
    "    mean, std = np.mean(data_clipped), np.std(data_clipped)\n",
    "    burst_threshold = mean + std*sigma\n",
    "    print('Calculated threshold ({}, sigma={})\\n'.format(\n",
    "        round(burst_threshold, 2),\n",
    "        round(sigma, 2)\n",
    "    ))\n",
    "\n",
    "    bursts = detect_bursts_from_envelope(mean_env, burst_threshold)\n",
    "    print('\\nBursts detected')\n",
    "    \n",
    "    bursts = combined_adjacent_bursts(bursts, mean_env, temporal_distance=0.2)\n",
    "    print('Combined adjacent bursts')\n",
    "    \n",
    "    bursts = filter_rms(bursts, max_rms=1000)\n",
    "    print('\\tFiltered RMS')\n",
    "\n",
    "    bursts = filter_short_bursts(bursts, minimum_duration)\n",
    "    print('Short bursts filtered')\n",
    "    \n",
    "    bursts = get_unfiltered_bursts(bursts, data_bandpass)\n",
    "    print('Got unfiltered bursts')\n",
    "    \n",
    "    bursts = filter_minimum_peaks(bursts, burst_threshold, minimum_peaks=minimum_peaks)\n",
    "    print('Filtered minimum thresold points')\n",
    "    \n",
    "    for burst in bursts:\n",
    "        burst.get_primary_frequency()\n",
    "    print('Primary frequencies computed')\n",
    "    \n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (recordings, get_mua=False, get_psd=False):\n",
    "    bursts = []\n",
    "    \n",
    "    for idx, recording in enumerate(recordings[:17]):\n",
    "        print(\"\\nRecording {} ({}/{})\".format(\n",
    "            recording[\"path\"],\n",
    "            idx+1,\n",
    "            len(recordings)\n",
    "        ))\n",
    "        \n",
    "        data_range = get_slice_from_s(0, 60*60)\n",
    "        recording_n = recording[\"recording\"]\n",
    "        striatum_channel_n = recording[\"striatum_channel\"]\n",
    "        thalamus_channel_n = recording[\"thalamus_channel\"] if recording[\"thalamus\"] else 0\n",
    "        cortex_channel_n = recording[\"cortex_channel\"]\n",
    "\n",
    "        session = Session(ROOT + recording[\"path\"])\n",
    "        striatum_data = session.recordings[recording_n].continuous[0].samples[data_range, striatum_channel_n]\n",
    "        thalamus_data = session.recordings[recording_n].continuous[0].samples[data_range, thalamus_channel_n]\n",
    "        cortex_data = session.recordings[recording_n].continuous[0].samples[data_range, cortex_channel_n]\n",
    "\n",
    "        minimum_duration = 0.2\n",
    "        minimum_peaks = 5\n",
    "        \n",
    "        recording = recording.copy()\n",
    "        \n",
    "        # Striatum\n",
    "        if len(striatum_data):\n",
    "            recording[\"length\"] = len(striatum_data)\n",
    "            recording[\"striatum_bursts\"]  = run_burst_procedure(\n",
    "                data=striatum_data,\n",
    "                minimum_peaks=minimum_peaks,\n",
    "                minimum_duration=minimum_duration,\n",
    "                sigma=recording[\"striatum_sigma\"]\n",
    "            )\n",
    "            if get_mua:\n",
    "                recording[\"striatum_MUA\"] = detect_MUA(\n",
    "                    data=striatum_data,\n",
    "                    standard_deviations=5\n",
    "                )\n",
    "            if get_psd:\n",
    "                recording[\"striatum_PSD\"] = multitaper_psd (\n",
    "                    striatum_data,\n",
    "                    NW=3, k=5, resample_freq=1000,\n",
    "                    show_progress=True\n",
    "                )\n",
    "                \n",
    "        # Thalamus\n",
    "        if len(thalamus_data) and recording[\"thalamus\"]:\n",
    "            recording[\"thalamus_bursts\"] = run_burst_procedure(\n",
    "                data=thalamus_data,\n",
    "                minimum_peaks=minimum_peaks,\n",
    "                minimum_duration=minimum_duration,\n",
    "                sigma=recording[\"thalamus_sigma\"]\n",
    "            )\n",
    "            if get_mua:\n",
    "                recording[\"thalamus_MUA\"] = detect_MUA(\n",
    "                    data=thalamus_data,\n",
    "                    standard_deviations=5\n",
    "                )\n",
    "            if get_psd:\n",
    "                recording[\"thalamus_PSD\"] = multitaper_psd (\n",
    "                    thalamus_data,\n",
    "                    NW=3, k=5, resample_freq=1000,\n",
    "                    show_progress=True\n",
    "                )\n",
    "        \n",
    "        # Cortex\n",
    "        if len(cortex_data):\n",
    "            recording[\"cortex_bursts\"]  = run_burst_procedure(\n",
    "                data=cortex_data,\n",
    "                minimum_peaks=minimum_peaks,\n",
    "                minimum_duration=minimum_duration,\n",
    "                sigma=recording[\"cortex_sigma\"]\n",
    "            )\n",
    "            if get_mua:\n",
    "                recording[\"cortex_MUA\"] = detect_MUA(\n",
    "                    data=cortex_data,\n",
    "                    standard_deviations=5\n",
    "                )\n",
    "            if get_psd:\n",
    "                recording[\"cortex_PSD\"] = multitaper_psd (\n",
    "                    cortex_data,\n",
    "                    NW=3, k=5, resample_freq=1000,\n",
    "                    show_progress=True\n",
    "                )\n",
    "\n",
    "        bursts.append(recording)\n",
    "\n",
    "    return bursts\n",
    "        \n",
    "processed_recordings = load_data(RECORDINGS, get_mua=False, get_psd=False)\n",
    "save_data(processed_recordings, 'processed_recording_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will find the baseline periods in a recording\n",
    "# Defined as those periods of signal not included as burst where \n",
    "# All time points are below the cut-off threshold above 0.5s in length\n",
    "\n",
    "# These baseline periods are trimmed to a max of 10s and the PSD for each is taken\n",
    "# These PSDs are then averaged giving the mean baseline PSD for each brain area and recording\n",
    "\n",
    "def get_baseline_periods (recording):\n",
    "    for brain_area in [\"striatum\", \"thalamus\", \"cortex\"]:\n",
    "        burst_key = brain_area + \"_bursts\"\n",
    "        if not burst_key in recording:\n",
    "            continue\n",
    "        \n",
    "        baseline_key = brain_area + \"_baseline\"\n",
    "        channel_key = brain_area + \"_channel\"\n",
    "        sigma_key = brain_area + \"_sigma\"\n",
    "        path, recording_n, channel_n = recording[\"path\"], recording[\"recording\"], recording[channel_key]\n",
    "        \n",
    "        session = Session(ROOT + path)\n",
    "        bursts = recording[burst_key]\n",
    "        \n",
    "        data = session.recordings[recording_n].continuous[0].samples[DATA_RANGE_ALL, channel_n]\n",
    "        data_bandpass = butter_bandpass_filter(data, lowcut=1, highcut=100)\n",
    "        data_clipped = np.clip(data_bandpass, a_min=-1000, a_max=1000)\n",
    "        print('Data filtered')\n",
    "        \n",
    "        burst_threshold = np.mean(data_clipped) + np.std(data_clipped)*recording[sigma_key]\n",
    "        print('Threshold calculated ({})'.format(burst_threshold))\n",
    "        \n",
    "        baseline_data = []\n",
    "        for burst_idx, burst in enumerate(bursts):\n",
    "            next_burst_time = None\n",
    "            \n",
    "            # If on last burst, baseline will last until end of recording\n",
    "            if burst_idx+1 == len(bursts):\n",
    "                next_burst_time = [len(data_bandpass)]\n",
    "            else:\n",
    "                next_burst_time = bursts[burst_idx+1].time\n",
    "                \n",
    "            curr_burst_time = burst.time  \n",
    "            data_raw = data_bandpass[curr_burst_time[1]:next_burst_time[0]]\n",
    "            \n",
    "            # If none of baseline period is above threshold\n",
    "            if len(np.where(data_raw > burst_threshold)[0]) == 0:\n",
    "                baseline_data.append(data_raw)\n",
    "\n",
    "        # Try again without threshold\n",
    "        if len(baseline_data) == 0:\n",
    "            print('Trying again without threshold')\n",
    "            for burst_idx, burst in enumerate(bursts):\n",
    "                next_burst_time = None\n",
    "\n",
    "                # If on last burst, baseline will last until end of recording\n",
    "                if burst_idx+1 == len(bursts):\n",
    "                    next_burst_time = [len(data_bandpass)]\n",
    "                else:\n",
    "                    next_burst_time = bursts[burst_idx+1].time\n",
    "\n",
    "                curr_burst_time = burst.time  \n",
    "                data_raw = data_bandpass[curr_burst_time[1]:next_burst_time[0]]\n",
    "                baseline_data.append(data_raw)\n",
    "\n",
    "        print('Baselines calculated')\n",
    "        \n",
    "        # Take mean of all baseline psd's\n",
    "        baseline_psds = []\n",
    "        for baseline in baseline_data:\n",
    "            if len(baseline)/30000 > 0.5:\n",
    "                baseline = baseline[get_slice_from_s(0, 10)] # Trim to max 10s\n",
    "                baseline_psds.append(multitaper_psd(baseline))\n",
    "\n",
    "        # If still no baseline periods, just leave it as 'False'\n",
    "        if len(baseline_psds):\n",
    "            f = baseline_psds[0][0]\n",
    "            Pxx = np.mean([psd[1] for psd in baseline_psds], axis=0)\n",
    "            recording[baseline_key] = f, Pxx\n",
    "        else:\n",
    "            recording[baseline_key] = False\n",
    "            print('None found')\n",
    "            \n",
    "    return recording\n",
    "    \n",
    "recordings_with_baselines = []\n",
    "for recording_idx, recording in enumerate(processed_recordings):\n",
    "    print(\"\\nRecording {} ({}/{})\".format(\n",
    "        recording[\"path\"],\n",
    "        recording_idx+1,\n",
    "        len(processed_recordings)\n",
    "    ))\n",
    "    recordings_with_baselines.append(get_baseline_periods(recording))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code takes the primary frequency of a burst as the peak in the PSD taken from the ratio\n",
    "# between the baseline and burst PSDs\n",
    "#\n",
    "# This will add a field \"primary_frequency_baseline\" to each burst across thalamus, striatum, cortex\n",
    "# for each recording\n",
    "# Simply change INPUT_RECORDINGS to variable holding the array of processed recordings\n",
    "\n",
    "INPUT_RECORDINGS = recordings_with_baselines\n",
    "\n",
    "for recording_idx, recording in enumerate(INPUT_RECORDINGS):\n",
    "    print(\"\\nRecording {} ({}/{})\".format(\n",
    "        recording[\"path\"],\n",
    "        recording_idx+1,\n",
    "        len(INPUT_RECORDINGS)\n",
    "    ))\n",
    "    \n",
    "    for brain_area in [\"striatum\", \"thalamus\", \"cortex\"]:\n",
    "        baseline_key = brain_area + \"_baseline\"\n",
    "        burst_key = brain_area + \"_bursts\"\n",
    "        \n",
    "        if not burst_key in recording:\n",
    "            continue\n",
    "            \n",
    "        f_baseline, Pxx_baseline = get_psd_in_range(recording[baseline_key], [1, 100])\n",
    "\n",
    "        for burst in recording[burst_key]:\n",
    "            # Take ratio between burst and baseline power\n",
    "            f_burst, Pxx_burst = get_psd_in_range(multitaper_psd(burst.data), [1, 100])\n",
    "            Pxx_ratio = Pxx_burst/Pxx_baseline\n",
    "            \n",
    "            # Anything above 1 indicates greater power for burst over baseline\n",
    "            Pxx_clipped = np.clip(Pxx_ratio, a_min=1, a_max=None)\n",
    "            \n",
    "            # Find max peak (primary freq) in burst/baseline power ratio\n",
    "            peaks = signal.find_peaks(Pxx_clipped)[0]\n",
    "            if len(peaks):\n",
    "                max_power = max(Pxx_clipped[peaks])\n",
    "                max_power_idx = np.where(Pxx_clipped == max_power)[0]\n",
    "                max_freq = f[max_power_idx][0]\n",
    "\n",
    "                burst.primary_frequency_baseline = max_freq\n",
    "            else:\n",
    "                burst.primary_frequency_baseline = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different burst detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on (but all code self-written) from https://www.frontiersin.org/articles/10.3389/fncir.2014.00050/full#F1\n",
    "\n",
    "def rms (data):\n",
    "    square = [d**2 for d in data]\n",
    "    mean = np.mean(square)\n",
    "    root = mean**0.5\n",
    "    return root\n",
    "\n",
    "def rms_hist(data, window=0.2):\n",
    "    rms_list = []\n",
    "    \n",
    "    chunk_size = int(SAMPLING_RATE*window) # Convert window in s to samples\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        data_chunk = data[i:i+chunk_size]\n",
    "        rms_list.append(rms(data_chunk))\n",
    "    \n",
    "    n_bins = int(np.percentile(rms_list, 95))\n",
    "    hist, bin_edges = np.histogram(rms_list, density=True, bins=n_bins, range=( min(rms_list), min(np.percentile(rms_list, 99), 2000) ))\n",
    "    \n",
    "    return hist, bin_edges, rms_list\n",
    "\n",
    "def plot_gaussian (bin_centres, hist, hist_fit):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(bin_centres, hist, label='RMS', c='tab:red')\n",
    "    plt.plot(bin_centres, hist_fit, label='Fitted Gaussian', c='black')\n",
    "    plt.xlabel('RMS')\n",
    "    plt.ylabel('Density')\n",
    "    \n",
    "    leg = plt.legend(frameon=False, fontsize=15, bbox_to_anchor=(0.925, 1), loc='upper left')\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(2.0)\n",
    "        \n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    for item in ([ax.title] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(12.5)\n",
    "    for item in ([ax.xaxis.label, ax.yaxis.label] + ax.get_legend().get_texts()):\n",
    "        item.set_fontsize(15)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def fit_gaussian(hist, bin_edges, use_truncated_hist):\n",
    "    bin_centres = (bin_edges[:-1] + bin_edges[1:])/2\n",
    "    \n",
    "    if False:\n",
    "        hist_100_idx = np.where(bin_centres <= 100)[0][-1]\n",
    "        trimmed_hist = hist[:hist_100_idx]\n",
    "        trimmed_bin_centres = bin_centres[:hist_100_idx]\n",
    "    else:\n",
    "        peak_idx = np.argmax(hist)\n",
    "    \n",
    "    peak_idx = np.argmax(hist)\n",
    "    peak = bin_centres[peak_idx]\n",
    "\n",
    "    def gauss(x, *p):\n",
    "        A, mu, sigma = p\n",
    "        return A*np.exp(-(x-mu)**2/(2.*sigma**2))\n",
    "\n",
    "    \n",
    "    p0 = [np.max(hist), peak, np.std(np.concatenate([np.repeat(c, int(v*1000)) for c,v in zip(bin_centres, hist)], axis=0))]\n",
    "    \n",
    "    coeff, var_matrix = curve_fit(gauss, trimmed_bin_centres, trimmed_hist, p0=p0)\n",
    "    _, mu, sigma = coeff\n",
    "    \n",
    "    hist_fit = gauss(bin_centres, *coeff)\n",
    "    \n",
    "    plot_gaussian (bin_centres, hist, hist_fit)\n",
    "    \n",
    "    smoothed_diff = hist_fit-hist\n",
    "    start_idx = np.where(bin_centres >= mu+sigma)[0][0]\n",
    "    thresh_idx = np.where(smoothed_diff[start_idx:] <= 0)[0][0] + start_idx + 1\n",
    "    thresh = bin_centres[thresh_idx]\n",
    "\n",
    "    return mu, abs(sigma), thresh\n",
    "\n",
    "def get_burst_events (data, rms_list, window=0.2, threshold=0):\n",
    "    bursts = []\n",
    "    \n",
    "    chunk_size = int(SAMPLING_RATE*window) # Convert window in s to samples\n",
    "    for chunk_idx, chunk_rms in enumerate(rms_list):\n",
    "        if chunk_rms > threshold:\n",
    "            t_start = chunk_idx*chunk_size\n",
    "            t_end = min(len(data), (chunk_idx+1)*chunk_size)\n",
    "            \n",
    "            burst = Burst([t_start, t_end], data[t_start:t_end])\n",
    "            bursts.append(burst)\n",
    "    \n",
    "    return bursts\n",
    "\n",
    "def combine_adjacent_bursts(data, bursts, temporal_distance):\n",
    "    combined_bursts = []\n",
    "    temp_bursts = []\n",
    "    \n",
    "    # Take first and last bursts and combine\n",
    "    def combine_bursts (temp_bursts):\n",
    "        start = temp_bursts[0].time[0]\n",
    "        end = temp_bursts[-1].time[1]\n",
    "        \n",
    "        return Burst([start, end], data[start:end])\n",
    "    \n",
    "    for burst_idx, burst in enumerate(bursts):    \n",
    "        if burst_idx == 0:\n",
    "            continue\n",
    "            \n",
    "        prev = bursts[burst_idx-1]\n",
    "        \n",
    "        prev_time = prev.time\n",
    "        curr_time = burst.time\n",
    "        \n",
    "        temp_bursts.append(prev)\n",
    "        \n",
    "        # If bursts are greater than x seconds apart\n",
    "        if (curr_time[0] - prev_time[1] > temporal_distance*SAMPLING_RATE):\n",
    "            combined_bursts.append(combine_bursts(temp_bursts))\n",
    "            temp_bursts = []\n",
    "        \n",
    "        # Or if on final burst of set\n",
    "        if burst_idx+1 == len(bursts):\n",
    "            temp_bursts.append(burst)\n",
    "            \n",
    "            combined_bursts.append(combine_bursts(temp_bursts))\n",
    "            temp_bursts = []\n",
    "            \n",
    "    return combined_bursts\n",
    "\n",
    "def filter_short_bursts (bursts, minimum_duration):\n",
    "    minimum_samples = minimum_duration*SAMPLING_RATE\n",
    "    \n",
    "    return [b for b in bursts if (b.time[1]-b.time[0]) >= minimum_samples]\n",
    "\n",
    "def filter_rms (bursts, max_rms):\n",
    "    filtered_bursts = []\n",
    "    \n",
    "    for burst in bursts:\n",
    "        rms_list = []\n",
    "        chunk_size = int(SAMPLING_RATE*0.2) # Convert window in s to samples\n",
    "        for i in range(0, len(burst.data), chunk_size):\n",
    "            data_chunk = burst.data[i:i+chunk_size]\n",
    "            rms_list.append(rms(data_chunk))\n",
    "        if np.max(rms_list) < max_rms:\n",
    "            filtered_bursts.append(burst)\n",
    "    \n",
    "    return filtered_bursts\n",
    "\n",
    "def filter_min_peaks (bursts, min_peaks):\n",
    "    filtered_bursts = []\n",
    "    \n",
    "    for burst in bursts:\n",
    "        _, n_peaks = get_peaks(burst.data)\n",
    "        \n",
    "        if n_peaks >= min_peaks:\n",
    "            filtered_bursts.append(burst)\n",
    "    \n",
    "    return filtered_bursts\n",
    "\n",
    "def get_raw_bursts (data, bursts):\n",
    "    unfiltered_bursts = []\n",
    "\n",
    "    for burst in bursts:\n",
    "        unfiltered_burst = Burst(\n",
    "            burst.time,\n",
    "            data[burst.time[0]:burst.time[1]]\n",
    "        )\n",
    "        unfiltered_bursts.append(unfiltered_burst)\n",
    "    \n",
    "    return unfiltered_bursts\n",
    "\n",
    "def get_baseline_power (data, bursts):\n",
    "    # Get baseline periods\n",
    "    baseline_data = []\n",
    "    for burst_idx, burst in enumerate(bursts):\n",
    "        # If on last burst, baseline will last until end of recording\n",
    "        if burst_idx+1 == len(bursts):\n",
    "            next_burst_time = [len(data)]\n",
    "        else:\n",
    "            next_burst_time = bursts[burst_idx+1].time\n",
    "\n",
    "        curr_burst_time = burst.time  \n",
    "        \n",
    "        baseline_period = data[curr_burst_time[1]:next_burst_time[0]]\n",
    "        # Minimum length of 1s\n",
    "        if len(baseline_period)/SAMPLING_RATE >= 1:\n",
    "            # Trim to max 10s\n",
    "            baseline_period = baseline_period[get_slice_from_s(0, 10)]\n",
    "            baseline_data.append(baseline_period)\n",
    "            \n",
    "    # Take mean of all baseline psd's\n",
    "    baseline_psds = []\n",
    "    for baseline_period in baseline_data:\n",
    "        baseline_psds.append(multitaper_psd(baseline_period))\n",
    "\n",
    "    # If no baseline periods, just leave it as 'False'\n",
    "    if len(baseline_psds):\n",
    "        f = baseline_psds[0][0]\n",
    "        Pxx = np.mean([psd[1] for psd in baseline_psds], axis=0)\n",
    "        return f, Pxx, baseline_data\n",
    "    else:\n",
    "        return False, False, False\n",
    "    \n",
    "def get_baseline_amplitude (data):\n",
    "    if data and len(data):\n",
    "        amps = []\n",
    "        for baseline_period in data:\n",
    "            baseline_period = butter_bandpass_filter(baseline_period, 4, 100)\n",
    "            amps.append(np.max(baseline_period)-np.min(baseline_period))\n",
    "        return np.mean(amps, axis=0) \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_normalized_psd (bursts, baseline_psd):\n",
    "    normalized_psd_bursts = []\n",
    "\n",
    "    for burst in bursts:\n",
    "        # Scale PSDs to 0-100 Hz\n",
    "        f_baseline, Pxx_baseline = get_psd_in_range(baseline_psd, [0, 100])\n",
    "        f_burst, Pxx_burst = get_psd_in_range(multitaper_psd(burst.data), [0, 100])\n",
    "        \n",
    "        # Take ratio between burst and baseline power\n",
    "        Pxx_normed = Pxx_burst/Pxx_baseline\n",
    "\n",
    "        # Anything above 1 indicates greater power for burst over baseline\n",
    "        Pxx_clipped = np.clip(Pxx_normed, a_min=1, a_max=None)\n",
    "\n",
    "        # Find max peak (primary freq) in burst/baseline power ratio\n",
    "        peaks = signal.find_peaks(Pxx_clipped)[0]\n",
    "        if len(peaks):\n",
    "            max_power = max(Pxx_clipped[peaks])\n",
    "            max_power_idx = np.where(Pxx_clipped == max_power)[0]\n",
    "            max_freq = f_burst[max_power_idx][0]\n",
    "            burst.normalized_psd = (f_burst, Pxx_normed)\n",
    "            burst.primary_frequency_baseline = max_freq\n",
    "        else:\n",
    "            burst.primary_frequency_baseline = False\n",
    "        \n",
    "        normalized_psd_bursts.append(burst)\n",
    "        \n",
    "    return normalized_psd_bursts\n",
    "\n",
    "rms_processed_recordings = []\n",
    "for recording_idx, recording in enumerate(RECORDINGS_NEW):    \n",
    "    print(\"P{} {}/{} {}\".format(recording[\"age\"], recording_idx+1, len(RECORDINGS_NEW), recording[\"path\"]))\n",
    "        \n",
    "    for brain_area in [\"cortex\"]: #, \"thalamus\", \"striatum\"]:\n",
    "        brain_channel = brain_area + \"_channel\"    \n",
    "        brain_bursts = brain_area + \"_bursts\"\n",
    "        brain_baseline = brain_area + \"_baseline\"\n",
    "        brain_baseline_amp = brain_area + \"_baseline_amplitude\"\n",
    "        \n",
    "        if not brain_channel in recording:\n",
    "            continue\n",
    "        else:\n",
    "            print('\\t{}'.format(brain_area))\n",
    "            \n",
    "        recording_n = recording[\"recording\"]\n",
    "        channel_n = recording[brain_channel]\n",
    "        session = Session(ROOT + recording[\"path\"])\n",
    "\n",
    "        data_all = session.recordings[recording_n].continuous[0].samples[get_slice_from_s(0, 60*60), channel_n]\n",
    "        data_all_4_to_100 = butter_bandpass_filter(data_all, 4, 100)\n",
    "        \n",
    "        hist, bin_edges, rms_list = rms_hist(data_all_4_to_100, window=0.2)\n",
    "        try:\n",
    "            mu, sigma, thresh = fit_gaussian(hist, bin_edges, use_truncated_hist=False)\n",
    "            thresh = max(thresh, mu+3*sigma)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Warning! Could not fit Gaussian!')\n",
    "            continue\n",
    "        print('\\tComputed mean ({}) and sigma ({}), threshold ({})'.format(mu, sigma, thresh))\n",
    "\n",
    "        bursts = get_burst_events(data_all_4_to_100, rms_list, window=0.2, threshold=thresh)\n",
    "        print('\\tBursts found')\n",
    "        bursts = combine_adjacent_bursts(data_all_4_to_100, bursts, temporal_distance=0.2)\n",
    "        print('\\tAdjacent bursts combined')\n",
    "        \n",
    "        baseline_f, baseline_Pxx, baseline_data = get_baseline_power(data_all, bursts)\n",
    "        baseline_psd = baseline_f, baseline_Pxx\n",
    "        print('\\tBaseline periods found')\n",
    "        baseline_amplitude = get_baseline_amplitude(baseline_data)\n",
    "        print('\\tBaseline amplitudes found')\n",
    "        \n",
    "        bursts = filter_short_bursts(bursts, minimum_duration=0.2)\n",
    "        print('\\tFiltered short bursts')\n",
    "        bursts = filter_rms(bursts, max_rms=1000)\n",
    "        print('\\tFiltered RMS')\n",
    "        bursts = filter_min_peaks(bursts, min_peaks=5)            \n",
    "        bursts = get_raw_bursts (data_all, bursts)\n",
    "        print('\\tGot 1500 Hz data')\n",
    "        \n",
    "        bursts = get_normalized_psd(bursts, baseline_psd)\n",
    "        print('\\tGot normed PSDs\\n')\n",
    "        \n",
    "        recording = recording.copy()\n",
    "        recording[brain_bursts] = bursts\n",
    "        recording[brain_baseline] = baseline_psd\n",
    "        recording[brain_baseline_amp] = baseline_amplitude\n",
    "        recording[\"length\"] = len(data_all)\n",
    "        \n",
    "    rms_processed_recordings.append(recording)\n",
    "\n",
    "    save_data(rms_processed_recordings, '') # Path to save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUA detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_recordings_mua = {}\n",
    "\n",
    "for recording_idx, recording in enumerate(RECORDINGS[-5:]):\n",
    "    print(\"P{} {}/{} {}\".format(recording[\"age\"], recording_idx+1, len(RECORDINGS), recording[\"path\"]))\n",
    "    \n",
    "    for brain_area in [\"cortex\"]: #, \"striatum\", \"thalamus\"]:\n",
    "        brain_channel = brain_area + \"_channel\"\n",
    "        brain_mua = brain_area + \"_mua\"\n",
    "        \n",
    "        if not brain_channel in recording:\n",
    "            continue\n",
    "        else:\n",
    "            print('\\t{}'.format(brain_area))\n",
    "\n",
    "        recording_n = recording[\"recording\"]\n",
    "        channel_n = recording[brain_channel]\n",
    "        session = Session(ROOT + recording[\"path\"])\n",
    "\n",
    "        data_all = session.recordings[recording_n].continuous[0].samples[get_slice_from_s(0, 60*60), channel_n]\n",
    "        \n",
    "        recording[\"length\"] = len(data_all) / SAMPLING_RATE\n",
    "        recording[brain_mua] = detect_MUA(data_all, 5)\n",
    "        \n",
    "        d = butter_bandpass_filter(data_all, 400, 4000).copy()\n",
    "        t_max = SAMPLING_RATE*5*60\n",
    "        \n",
    "    processed_recordings_mua[recording['path']] = recording"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk]",
   "language": "python",
   "name": "conda-env-allensdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
