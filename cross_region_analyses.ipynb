{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from utilities import *\n",
    "from recording_data import RECORDINGS\n",
    "from clustering import (\n",
    "    feature_vector_labels, feature_vector_labels_full,\n",
    "    get_feature_vectors, get_cluster_labels, sort_bursts_by_labels\n",
    ")\n",
    "from xcorr import correlate_template\n",
    "from detect_mua import detect_MUA, get_spike_wave_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open previously saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_processed_recordings = open_data('') # Path to processed data (pickle file format)\n",
    "processed_recordings_mua = open_data('') # Path to processed data (pickle file format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['thalamus', 'cortex', 'striatum']:\n",
    "    all_bursts, all_features = get_feature_vectors (\n",
    "        rms_processed_recordings,\n",
    "        processed_recordings_mua,\n",
    "        key=key+'_bursts', mua_key=key+'_mua'\n",
    "    )\n",
    "    \n",
    "    labels, pca = get_cluster_labels(all_features)\n",
    "    feature_list_ngb, feature_list_sb, bursts_ngb, bursts_sb = sort_bursts_by_labels(\n",
    "        all_bursts, all_features, labels\n",
    "    )\n",
    "    \n",
    "    if key == 'thalamus':\n",
    "        thalamus_ngb_features = feature_list_ngb\n",
    "        thalamus_sb_features = feature_list_sb\n",
    "        thalamus_ngb = bursts_ngb\n",
    "        thalamus_sb = bursts_sb\n",
    "    if key == 'striatum':\n",
    "        striatum_ngb_features = feature_list_ngb\n",
    "        striatum_sb_features = feature_list_sb\n",
    "        striatum_ngb = bursts_ngb\n",
    "        striatum_sb = bursts_sb\n",
    "    if key == 'cortex':\n",
    "        cortex_ngb_features = feature_list_ngb\n",
    "        cortex_sb_features = feature_list_sb\n",
    "        cortex_ngb = bursts_ngb\n",
    "        cortex_sb = bursts_sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d_for_welch (a, b):\n",
    "    return (np.mean(a) - np.mean(b)) / np.sqrt((np.var(a) + np.var(b)) / 2)\n",
    "\n",
    "def align_overlapping_bursts (burst_a, burst_b):\n",
    "    start_overlap = max(burst_a.time[0], burst_b.time[0])\n",
    "    end_overlap = min(burst_a.time[1], burst_b.time[1])\n",
    "    \n",
    "    \n",
    "    start_a = start_overlap-burst_a.time[0]\n",
    "    end_a = start_a + (end_overlap-start_overlap)\n",
    "    start_b = start_overlap-burst_b.time[0]\n",
    "    end_b = start_b + (end_overlap-start_overlap)\n",
    "    \n",
    "    burst_a_trimmed = burst_a.data[start_a:end_a]\n",
    "    burst_b_trimmed = burst_b.data[start_b:end_b]\n",
    "    \n",
    "    return (\n",
    "        burst_a_trimmed,\n",
    "        burst_b_trimmed,\n",
    "        get_xticks(slice(start_overlap, end_overlap))\n",
    "    )\n",
    "\n",
    "def get_threshold (burst_pairs):\n",
    "    f_arr = None\n",
    "    Cxy_arr = []\n",
    "    \n",
    "    a_burst, b_burst = burst_pairs[0]\n",
    "    a, b, xticks = align_overlapping_bursts(a_burst, b_burst)\n",
    "    for iteration in range(200):\n",
    "        np.random.shuffle(a)\n",
    "        np.random.shuffle(b)\n",
    "\n",
    "        window_size = 0.5\n",
    "        window = int(SAMPLING_RATE*window_size)\n",
    "        overlap = int(SAMPLING_RATE*window_size*0.5)\n",
    "        f, Cxy = signal.coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "                \n",
    "        f, Cxy = get_psd_in_range((f, Cxy), [0, 100])\n",
    "        \n",
    "\n",
    "        plt.plot(a)\n",
    "        plt.plot(b)\n",
    "        plt.show()\n",
    "\n",
    "        f_arr = f\n",
    "        Cxy_arr.append(Cxy)\n",
    "        \n",
    "    Cxy_arr = np.array(Cxy_arr)\n",
    "\n",
    "    return np.percentile(Cxy_arr, 95, axis=0)\n",
    "\n",
    "def get_lags (burst_a_data, burst_b_data, freq, prewhiten):\n",
    "    burst_a_data = butter_bandpass_filter(burst_a_data, freq[0], freq[1])\n",
    "    burst_b_data = butter_bandpass_filter(burst_b_data, freq[0], freq[1])\n",
    "        \n",
    "    # Get instantaneous amplitude\n",
    "    analytic_signal_a = signal.hilbert(burst_a_data)\n",
    "    amplitude_a = np.abs(analytic_signal_a)\n",
    "    amplitude_a = amplitude_a - np.mean(amplitude_a)\n",
    "    \n",
    "    analytic_signal_b = signal.hilbert(burst_b_data)\n",
    "    amplitude_b = np.abs(analytic_signal_b)\n",
    "    amplitude_b = amplitude_b - np.mean(amplitude_b)\n",
    "    \n",
    "    # Pre-whiten\n",
    "    if prewhiten:\n",
    "        model_a = ARIMA(amplitude_a, order=(1,0,1))\n",
    "        fit_a = model_a.fit()\n",
    "        \n",
    "        a_resid = fit_a.resid        \n",
    "        a, b = a_resid, amplitude_b\n",
    "    else:\n",
    "        a = amplitude_a\n",
    "        b = amplitude_b\n",
    "\n",
    "    # Get cross-correlation\n",
    "    cross_corr = correlate_template(a, b, mode='full', normalize='naive', demean=False)\n",
    "\n",
    "    # Take only +/- 100ms from 0 lag\n",
    "    centre = int(len(cross_corr) * 0.5)\n",
    "    hundred_ms = int(SAMPLING_RATE*0.1)\n",
    "    cross_corr = cross_corr[centre-hundred_ms:centre+hundred_ms]\n",
    "\n",
    "    # Square results\n",
    "    cross_corr_sq = cross_corr**2\n",
    "    \n",
    "    # Convert time points into ms\n",
    "    xpos = np.linspace(-hundred_ms, hundred_ms, len(cross_corr))\n",
    "    xpos = xpos / (SAMPLING_RATE) * 1000\n",
    "    \n",
    "    return xpos, cross_corr_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get co-occuring bursts across regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping_bursts (bursts_a, bursts_b, bursts_c=None):\n",
    "    # maximum difference in start times considered overlapping\n",
    "    max_t_diff = 0.5\n",
    "    burst_pairs = []\n",
    "\n",
    "    for a_idx, burst_a in enumerate(bursts_a):\n",
    "        start_t_a = burst_a.time[0]\n",
    "        \n",
    "        for burst_b in bursts_b:\n",
    "            start_t_b = burst_b.time[0]\n",
    "            \n",
    "            if bursts_c:\n",
    "                for burst_c in bursts_c:\n",
    "                    start_t_c = burst_c.time[0]\n",
    "                    \n",
    "                    t_diff_ab = abs(start_t_a - start_t_b)\n",
    "                    t_diff_ac = abs(start_t_a - start_t_c)\n",
    "                    t_diff_bc = abs(start_t_b - start_t_c)\n",
    "                    \n",
    "                    max_diff = max(t_diff_ab, t_diff_ac, t_diff_bc)\n",
    "                    min_len = min(len(burst_a.data), len(burst_b.data), len(burst_c.data))\n",
    "                    \n",
    "                    if max_diff < (SAMPLING_RATE*max_t_diff) and max_diff < min_len:\n",
    "                        burst_pairs.append(\n",
    "                            { \"bursts\": [burst_a, burst_b, burst_c], \"hash\": hash(burst_a)+hash(burst_b)+hash(burst_c) }\n",
    "                        )\n",
    "            else:\n",
    "                t_diff = abs(start_t_a - start_t_b)\n",
    "                if t_diff < (SAMPLING_RATE*max_t_diff) and t_diff < min(len(burst_a.data), len(burst_b.data)):\n",
    "                    burst_pairs.append(\n",
    "                        { \"bursts\": [burst_a, burst_b], \"hash\": hash(burst_a)+hash(burst_b) }\n",
    "                    )\n",
    "    \n",
    "    burst_pairs = np.array(burst_pairs)\n",
    "    unique_burst_pair_idxs = np.unique([pair[\"hash\"] for pair in burst_pairs], return_index=True)[1]\n",
    "    unique_burst_pairs = burst_pairs[unique_burst_pair_idxs]\n",
    "    unique_burst_pairs = [pair[\"bursts\"] for pair in burst_pairs]\n",
    "    \n",
    "    return unique_burst_pairs\n",
    "\n",
    "def get_nonoverlapping_bursts (bursts_a, bursts_b, burst_pairs):\n",
    "    bursts_a_nonoverlapping = []\n",
    "    for burst_a in bursts_a:\n",
    "        is_overlapping = False\n",
    "        for burst_pair in burst_pairs:\n",
    "            if burst_a in burst_pair:\n",
    "                is_overlapping = True\n",
    "                break\n",
    "        if not is_overlapping:\n",
    "            bursts_a_nonoverlapping.append(burst_a)\n",
    "\n",
    "    bursts_b_nonoverlapping = []\n",
    "    for burst_b in bursts_b:\n",
    "        is_overlapping = False\n",
    "        for burst_pair in burst_pairs:\n",
    "            if burst_b in burst_pair:\n",
    "                is_overlapping = True\n",
    "                break\n",
    "        if not is_overlapping:\n",
    "            bursts_b_nonoverlapping.append(burst_b)\n",
    "      \n",
    "    return bursts_a_nonoverlapping, bursts_b_nonoverlapping\n",
    "\n",
    "cooccuring_events = {\n",
    "    \"Thal-CP\": [],\n",
    "    \"Ctx-CP\": [],\n",
    "    \"Ctx-thal\": [],\n",
    "    \"Ctx-thal-CP\": []\n",
    "}\n",
    "\n",
    "cooccuring_events_by_age = {\n",
    "    \"Thal-CP\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"Ctx-CP\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"Ctx-thal\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"Ctx-thal-CP\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "nonoverlapping_events = {\n",
    "    \"thalamus\": [],\n",
    "    \"striatum\": [],\n",
    "    \"cortex\": []\n",
    "}\n",
    "\n",
    "proportion_cooccuring_events = {\n",
    "    \"Thal-CP\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"Ctx-CP\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"Ctx-thal\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"Ctx-thal-CP\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "proportion_nonoverlapping_events = {\n",
    "    \"thalamus\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"striatum\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    },\n",
    "    \"cortex\": {\n",
    "        \"5-6\": [],\n",
    "        \"7-8\": [],\n",
    "        \"9-10\": [],\n",
    "        \"11-12\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "for recording_idx, recording in enumerate(rms_processed_recordings):    \n",
    "    if recording[\"age\"] < 7:\n",
    "        age = \"5-6\"\n",
    "    elif recording[\"age\"] >= 7 and recording[\"age\"] < 9:\n",
    "        age = \"7-8\"\n",
    "    elif recording[\"age\"] >= 9 and recording[\"age\"] < 11:\n",
    "        age = \"9-10\"\n",
    "    elif recording[\"age\"] >= 11 and recording[\"age\"] < 13:\n",
    "        age = \"11-12\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    print(\"{}/{}\".format(recording_idx+1, len(rms_processed_recordings)))\n",
    "    \n",
    "    Ctx_CP = get_overlapping_bursts (recording[\"cortex_bursts\"], recording[\"striatum_bursts\"])\n",
    "    \n",
    "    nonoverlapping_events_ctx = []\n",
    "    nonoverlapping_events_cp = []\n",
    "    nonoverlapping_events_thal = []\n",
    "            \n",
    "    cooccuring_events[\"Ctx-CP\"] += Ctx_CP\n",
    "    cooccuring_events_by_age[\"Ctx-CP\"][age] += Ctx_CP\n",
    "    proportion_cooccuring_events[\"Ctx-CP\"][age].append(\n",
    "        len(Ctx_CP) / (len(recording[\"cortex_bursts\"]) + len(recording[\"striatum_bursts\"]))\n",
    "    )\n",
    "    \n",
    "    if \"thalamus_bursts\" in recording:\n",
    "        Thal_CP = get_overlapping_bursts (recording[\"thalamus_bursts\"], recording[\"striatum_bursts\"])\n",
    "        cooccuring_events[\"Thal-CP\"] += Thal_CP\n",
    "        cooccuring_events_by_age[\"Thal-CP\"][age] += Thal_CP\n",
    "        proportion_cooccuring_events[\"Thal-CP\"][age].append(\n",
    "            len(Thal_CP) / (len(recording[\"thalamus_bursts\"]) + len(recording[\"striatum_bursts\"]))\n",
    "        )\n",
    "        \n",
    "        Ctx_thal = get_overlapping_bursts (recording[\"cortex_bursts\"], recording[\"thalamus_bursts\"])\n",
    "        cooccuring_events[\"Ctx-thal\"] += Ctx_thal\n",
    "        cooccuring_events_by_age[\"Ctx-thal\"][age] += Ctx_thal\n",
    "        proportion_cooccuring_events[\"Ctx-thal\"][age].append(\n",
    "            len(Ctx_thal) / (len(recording[\"cortex_bursts\"]) + len(recording[\"thalamus_bursts\"]))\n",
    "        )\n",
    "        \n",
    "        Ctx_thal_CP = get_overlapping_bursts (recording[\"cortex_bursts\"], recording[\"thalamus_bursts\"], recording[\"striatum_bursts\"])\n",
    "        cooccuring_events[\"Ctx-thal-CP\"] += Ctx_thal_CP\n",
    "        cooccuring_events_by_age[\"Ctx-thal-CP\"][age] += Ctx_thal_CP\n",
    "        proportion_cooccuring_events[\"Ctx-thal-CP\"][age].append(\n",
    "            len(Ctx_thal_CP) / (len(recording[\"cortex_bursts\"]) + len(recording[\"thalamus_bursts\"]) + len(recording[\"striatum_bursts\"]))\n",
    "        )\n",
    "        \n",
    "    def unique_list (l):\n",
    "        temp = []\n",
    "        for i in l:\n",
    "            if i in temp:\n",
    "                continue\n",
    "            else:\n",
    "                temp.append(i)\n",
    "        return temp\n",
    "                \n",
    "    proportion_nonoverlapping_events['cortex'][age].append(\n",
    "        len(unique_list(nonoverlapping_events_ctx))/len(recording[\"cortex_bursts\"])\n",
    "    )\n",
    "    if \"thalamus_bursts\" in recording:\n",
    "        proportion_nonoverlapping_events['thalamus'][age].append(\n",
    "            len(unique_list(nonoverlapping_events_thal))/len(recording[\"thalamus_bursts\"])\n",
    "        )\n",
    "    proportion_nonoverlapping_events['striatum'][age].append(\n",
    "        len(unique_list(nonoverlapping_events_cp))/len(recording[\"striatum_bursts\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike-spike cross-correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_spike_crosscorr (burst_pair, shuffle):\n",
    "    burst_a, burst_b = burst_pair\n",
    "    a, b, _ = align_overlapping_bursts(burst_a, burst_b)\n",
    "    \n",
    "    spikes_a_times, _ = detect_MUA(a, 4, silent=True)\n",
    "    spikes_a = np.zeros(len(a))\n",
    "    for t in spikes_a_times:\n",
    "        spikes_a[t] = 1\n",
    "    \n",
    "    spikes_b_times, _ = detect_MUA(b, 4, silent=True)\n",
    "    spikes_b = np.zeros(len(b))\n",
    "    for t in spikes_b_times:\n",
    "        spikes_b[t] = 1\n",
    "    \n",
    "    if len(spikes_a_times) < 30 or len(spikes_b_times) < 30:\n",
    "        return np.nan\n",
    "    \n",
    "    spikes_a = ndimage.gaussian_filter1d(spikes_a, int(SAMPLING_RATE/1000 * 2))\n",
    "    spikes_b = ndimage.gaussian_filter1d(spikes_b, int(SAMPLING_RATE/1000 * 2))\n",
    "    \n",
    "    cross_corr = correlate_template(spikes_a, spikes_b, mode='full', normalize='naive', demean=False)\n",
    "    \n",
    "    # Take only +/- 5ms from 0 lag\n",
    "    centre = int(len(cross_corr) * 0.5)\n",
    "    ten_ms = int(SAMPLING_RATE/1000 * 10)\n",
    "    cross_corr = cross_corr[centre-ten_ms:centre+ten_ms]\n",
    "\n",
    "    # Square results\n",
    "    cross_corr_sq = cross_corr**2\n",
    "    \n",
    "    return cross_corr_sq, swfs_b, swfs_b\n",
    "    \n",
    "# Store the coherence spectra of each pair of co-occuring events\n",
    "cross_corr_arr = []\n",
    "for burst_pair_idx, burst_pair in enumerate(cooccuring_events[\"Ctx-CP\"]):\n",
    "    if (burst_pair_idx+1) % 100 == 0:\n",
    "        print('Burst pair', burst_pair_idx+1)\n",
    "        \n",
    "    cross_corr = get_spike_spike_crosscorr (burst_pair, shuffle=False)\n",
    "    if cross_corr is not np.nan:\n",
    "        cross_corr_arr.append(cross_corr)\n",
    "        \n",
    "mean_cross_corr = np.mean(cross_corr_arr, axis=0)\n",
    "err_cross_corr = np.std(cross_corr_arr, axis=0)/len(cross_corr_arr)**0.5\n",
    "\n",
    "ten_ms = int(SAMPLING_RATE/1000 * 10)\n",
    "xpos = np.linspace(-ten_ms, ten_ms, len(mean_cross_corr)) / (SAMPLING_RATE) * 1000\n",
    "        \n",
    "plt.plot(xpos, mean_cross_corr)\n",
    "plt.fill_between(xpos, mean_cross_corr+err_cross_corr, mean_cross_corr-err_cross_corr, alpha=0.2)\n",
    "plt.xlabel('Lag in ms')\n",
    "plt.ylabel('Squared cross-correlation')\n",
    "format_plot(plt.gca(), legend=False)\n",
    "plt.show()\n",
    "\n",
    "def get_cross_correlation_lag_peak (xpos, cross_corr):\n",
    "    peak_idxs = signal.find_peaks(cross_corr)[0]\n",
    "    \n",
    "    if len(peak_idxs):\n",
    "        peak_heights = np.array(cross_corr)[peak_idxs]\n",
    "        max_peak_position = xpos[peak_idxs[np.argmax(peak_heights)]]\n",
    "        \n",
    "        return max_peak_position\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "lags = [get_cross_correlation_lag_peak (xpos, cross_corr) for cross_corr in cross_corr_arr]\n",
    "lags = [lag for lag in lags if np.isfinite(lag)]\n",
    "\n",
    "plt.hist(lags, density=True)\n",
    "plt.title(f'Lag distribution, mean = {round(np.mean(lags), 2)}ms')\n",
    "plt.xlabel('Lag in ms')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "np.mean(lags), stats.ttest_1samp(lags, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike-LFP coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResampleLinear1D(original, targetLen):\n",
    "    original = np.array(original, dtype=np.float)\n",
    "    index_arr = np.linspace(0, len(original)-1, num=targetLen, dtype=np.float)\n",
    "    index_floor = np.array(index_arr, dtype=np.int) #Round down\n",
    "    index_ceil = index_floor + 1\n",
    "    index_rem = index_arr - index_floor #Remain\n",
    "\n",
    "    val1 = original[index_floor]\n",
    "    val2 = original[index_ceil % len(original)]\n",
    "    interp = val1 * (1.0-index_rem) + val2 * index_rem\n",
    "    assert(len(interp) == targetLen)\n",
    "    return interp\n",
    "\n",
    "# Bin width = 60 time points or 2ms\n",
    "bin_width = SAMPLING_RATE//1000 *2\n",
    "# Giving a sampling frequency of 500 Hz\n",
    "fs = 500\n",
    "# Use a window of 0.5s\n",
    "window = 250\n",
    "# With 0 overlap\n",
    "overlap = 0\n",
    "\n",
    "def get_spike_lfp_coherence (burst_pair, shuffle):\n",
    "    burst_a, burst_b = burst_pair\n",
    "    b, a, _ = align_overlapping_bursts(burst_a, burst_b)\n",
    "    \n",
    "    spikes_b_times, spikes_b_wf = detect_MUA(b, 4, silent=True)\n",
    "    spikes_b, _ = np.histogram(spikes_b_times, np.arange(0, len(b)+1, bin_width))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(spikes_b)\n",
    "    \n",
    "    # Filter in 4-80 Hz range\n",
    "    lfp_a = butter_bandpass_filter(a, 4, 80)\n",
    "    # Then resample at 500 Hz (same as spike train hist)\n",
    "    lfp_a = ResampleLinear1D(a, len(spikes_b))\n",
    "    \n",
    "    if len(lfp_a) < window or len(spikes_b_times) < 10:\n",
    "        return np.nan, np.nan\n",
    "    else:\n",
    "        f, Cxy = signal.coherence(lfp_a, spikes_b, fs=fs, nperseg=window, noverlap=overlap)\n",
    "        f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "        return f, Cxy\n",
    "\n",
    "# Store the coherence spectra of each pair of co-occuring events\n",
    "Cxy_arr = []\n",
    "for burst_pair_idx, burst_pair in enumerate(cooccuring_events[\"Ctx-CP\"]):\n",
    "    if (burst_pair_idx+1) % 100 == 0:\n",
    "        print('Burst pair', burst_pair_idx+1)\n",
    "        \n",
    "    f, Cxy = get_spike_lfp_coherence (burst_pair, shuffle=False)\n",
    "    if Cxy is not np.nan:\n",
    "        Cxy_arr.append(Cxy)\n",
    "    \n",
    "    \n",
    "# Cxy_arr\n",
    "Cxy_arr_shuffled = []\n",
    "for shuffle_iteration in range(1000):\n",
    "    print('Shuffle', shuffle_iteration + 1)\n",
    "    Cxy_arr_shuffled_iteration = []\n",
    "    \n",
    "    for burst_pair_idx, burst_pair in enumerate(cooccuring_events[\"Ctx-CP\"]):\n",
    "        f, Cxy = get_spike_lfp_coherence (burst_pair, shuffle=True)\n",
    "        if Cxy is not np.nan:\n",
    "            Cxy_arr_shuffled_iteration.append(Cxy)\n",
    "        \n",
    "    Cxy_arr_shuffled.append( np.mean(Cxy_arr_shuffled_iteration, axis=0) )\n",
    "    \n",
    "y = np.mean(Cxy_arr, axis=0)\n",
    "err = np.std(Cxy_arr, axis=0)/len(Cxy_arr)**0.5\n",
    "plt.plot(f, y)\n",
    "plt.fill_between(f, y+err, y-err, alpha=0.5)\n",
    "\n",
    "y = np.nanpercentile(Cxy_arr_shuffled, 95, axis=0)\n",
    "plt.plot(f, y, label='Shuffled')\n",
    "\n",
    "y = np.nanpercentile(Cxy_arr_shuffled, 5, axis=0)\n",
    "plt.plot(f, y, label='Shuffled')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proportion of co-occuring events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {\n",
    "    '5-6': [],\n",
    "    '7-8': [],\n",
    "    '9-10': [],\n",
    "    '11-12': []\n",
    "}\n",
    "\n",
    "for area_name, v in proportion_cooccuring_events.items():\n",
    "    for k, i in v.items():\n",
    "        values[k] += i\n",
    "    \n",
    "print(' 5-6 vs. 7-8', stats.ttest_ind(values['5-6'], values['7-8'], equal_var=False))\n",
    "print(' 7-8 vs. 9-10', stats.ttest_ind(values['7-8'], values['9-10'], equal_var=False))\n",
    "print(' 9-10 vs. 11-12', stats.ttest_ind(values['9-10'], values['11-12'], equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate proportions (over all ages)\n",
    "bar_means = []\n",
    "bar_stderrs = []\n",
    "bar_labels = []\n",
    "    \n",
    "for comparison in proportion_cooccuring_events.keys():\n",
    "    data = sum([val for val in proportion_cooccuring_events[comparison].values()], [])\n",
    "    mean = np.mean(data)\n",
    "    stderr = np.std(data) / len(data)\n",
    "    \n",
    "    bar_means.append(mean)\n",
    "    bar_stderrs.append(stderr)\n",
    "    bar_labels.append(comparison)\n",
    "xpos = np.arange(len(bar_means))    \n",
    "        \n",
    "plt.bar(xpos, bar_means, yerr=bar_stderrs, capsize=5, color=[\"tab:blue\", \"tab:orange\", 'tab:green', 'tab:red'])\n",
    "plt.xticks(xpos, bar_labels)\n",
    "plt.ylabel('Proportion of total events')\n",
    "format_plot(plt.gca(), legend=False)\n",
    "plt.show()\n",
    "\n",
    "# Bonferonni correction for multiple comparisons\n",
    "correction_val = 6\n",
    "for comparison_a in proportion_cooccuring_events.keys():\n",
    "    data_a = sum([val for val in proportion_cooccuring_events[comparison_a].values()], [])\n",
    "    for comparison_b in proportion_cooccuring_events.keys():\n",
    "        if comparison_a == comparison_b:\n",
    "            continue\n",
    "        \n",
    "        data_b = sum([val for val in proportion_cooccuring_events[comparison_b].values()], [])\n",
    "        \n",
    "        t, p = stats.ttest_ind(data_a, data_b, equal_var=False)\n",
    "        if p*correction_val < 0.05:\n",
    "            disp = '{} (mn={}, std={}) vs {} (mn={}, std={})\\nt={}, p corrected={}, dof={}\\n\\n'.format(\n",
    "                comparison_a, np.mean(data_a), np.std(data_a),\n",
    "                comparison_b, np.mean(data_b), np.std(data_b),\n",
    "                t, p*correction_val, welch_dof(data_a, data_b)\n",
    "            )\n",
    "            print(disp)\n",
    "\n",
    "            \n",
    "# By age\n",
    "for comparison in proportion_cooccuring_events.keys():\n",
    "    data_by_age = proportion_cooccuring_events[comparison]\n",
    "    \n",
    "    labels = []\n",
    "    means = []\n",
    "    stderrs = []\n",
    "    \n",
    "    for data, label in zip(data_by_age.values(), data_by_age.keys()):\n",
    "        if len(data):\n",
    "            means.append(np.mean(data))\n",
    "            stderrs.append(np.std(data) / len(data)**0.5)\n",
    "            labels.append(label)\n",
    "          \n",
    "    xpos = np.arange(len(labels))\n",
    "    means = np.array(means)\n",
    "    stderrs = np.array(stderrs)\n",
    "        \n",
    "    plt.plot(xpos, means, label=comparison)\n",
    "    plt.fill_between(xpos, means-stderrs, means+stderrs, alpha=0.25)\n",
    "    plt.xticks(xpos, labels)\n",
    "    \n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Proportion of total events')\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "format_plot(plt.gca(), legend=True)\n",
    "plt.show()\n",
    "\n",
    "print(twoway_anova(proportion_cooccuring_events, ['burst_pair', 'age', 'values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_burst_frequency = {\n",
    "    'both_ngb': {\n",
    "        'Thal-CP': [],\n",
    "        'Ctx-CP': [],\n",
    "        'Ctx-thal': []\n",
    "    },\n",
    "    'both_sb': {\n",
    "        'Thal-CP': [],\n",
    "        'Ctx-CP': [],\n",
    "        'Ctx-thal': []\n",
    "    },\n",
    "    'mixed': {\n",
    "        'Thal-CP': [],\n",
    "        'Ctx-CP': [],\n",
    "        'Ctx-thal': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"Ctx-CP\"\n",
    "\n",
    "for recording in rms_processed_recordings:\n",
    "    if not \"thalamus_bursts\" in recording:\n",
    "        continue\n",
    "    \n",
    "    recording_ngb = []\n",
    "    recording_sb = []\n",
    "    \n",
    "    recording_ngb_pairs = []\n",
    "    recording_sb_pairs = []\n",
    "    recording_mixed_pairs = []\n",
    "\n",
    "    # By burst type\n",
    "    for burst_pair in cooccuring_events[key]:\n",
    "        if not burst_pair[0] in recording[\"cortex_bursts\"]:\n",
    "            continue\n",
    "\n",
    "        if False:\n",
    "            ctx_burst, thal_burst = burst_pair\n",
    "            if ctx_burst in cortex_ngb and thal_burst in thalamus_ngb:\n",
    "                recording_ngb_pairs.append(burst_pair)\n",
    "                recording_ngb.append(ctx_burst)\n",
    "                recording_ngb.append(thal_burst)\n",
    "            elif ctx_burst in cortex_sb and thal_burst in thalamus_sb:\n",
    "                recording_sb_pairs.append(burst_pair)\n",
    "                recording_sb.append(ctx_burst)\n",
    "                recording_sb.append(thal_burst)\n",
    "            elif ctx_burst in cortex_ngb and thal_burst in thalamus_sb:\n",
    "                recording_mixed_pairs.append(burst_pair)\n",
    "                recording_ngb.append(ctx_burst)\n",
    "                recording_sb.append(thal_burst)\n",
    "            elif ctx_burst in cortex_sb and thal_burst in thalamus_ngb:\n",
    "                recording_mixed_pairs.append(burst_pair) \n",
    "                recording_sb.append(ctx_burst)\n",
    "                recording_ngb.append(thal_burst)\n",
    "\n",
    "        elif False:\n",
    "            thal_burst, cp_burst = burst_pair\n",
    "            if thal_burst in thalamus_ngb and cp_burst in striatum_ngb:\n",
    "                recording_ngb_pairs.append(burst_pair)\n",
    "                recording_ngb.append(thal_burst)\n",
    "                recording_ngb.append(cp_burst)\n",
    "            elif thal_burst in thalamus_sb and cp_burst in striatum_sb:\n",
    "                recording_sb_pairs.append(burst_pair)\n",
    "                recording_sb.append(thal_burst)\n",
    "                recording_sb.append(cp_burst)\n",
    "            elif thal_burst in thalamus_ngb and cp_burst in striatum_sb:\n",
    "                recording_mixed_pairs.append(burst_pair)\n",
    "                recording_ngb.append(thal_burst)\n",
    "                recording_sb.append(cp_burst)\n",
    "            elif thal_burst in thalamus_sb and cp_burst in striatum_ngb:\n",
    "                recording_mixed_pairs.append(burst_pair) \n",
    "                recording_sb.append(thal_burst)\n",
    "                recording_ngb.append(cp_burst)\n",
    "        elif True:\n",
    "            ctx_burst, cp_burst = burst_pair\n",
    "            if ctx_burst in cortex_ngb and cp_burst in striatum_ngb:\n",
    "                recording_ngb_pairs.append(burst_pair)\n",
    "                recording_ngb.append(ctx_burst)\n",
    "                recording_ngb.append(cp_burst)\n",
    "            elif ctx_burst in cortex_sb and cp_burst in striatum_sb:\n",
    "                recording_sb_pairs.append(burst_pair)\n",
    "                recording_sb.append(ctx_burst)\n",
    "                recording_sb.append(cp_burst)\n",
    "            elif ctx_burst in cortex_ngb and cp_burst in striatum_sb:\n",
    "                recording_mixed_pairs.append(burst_pair)\n",
    "                recording_ngb.append(ctx_burst)\n",
    "                recording_sb.append(cp_burst)\n",
    "            elif ctx_burst in cortex_sb and cp_burst in striatum_ngb:\n",
    "                recording_mixed_pairs.append(burst_pair) \n",
    "                recording_sb.append(ctx_burst)\n",
    "                recording_ngb.append(cp_burst)\n",
    "\n",
    "            \n",
    "    if len(recording_ngb_pairs):\n",
    "        normalized_burst_frequency['both_ngb'][key].append( len(recording_ngb_pairs) / len(recording_ngb) )\n",
    "    if len(recording_sb_pairs):\n",
    "        normalized_burst_frequency['both_sb'][key].append( len(recording_sb_pairs) / len(recording_sb) )\n",
    "    if len(recording_mixed_pairs):\n",
    "        normalized_burst_frequency['mixed'][key].append( len(recording_mixed_pairs) / (len(recording_ngb)+len(recording_sb)) )\n",
    "\n",
    "ngb_pairs = normalized_burst_frequency['both_ngb'][key]\n",
    "sb_pairs = normalized_burst_frequency['both_sb'][key]\n",
    "mixed_pairs = normalized_burst_frequency['mixed'][key]\n",
    "        \n",
    "xpos = np.arange(3)\n",
    "yvals = [np.mean(ngb_pairs), np.mean(sb_pairs), np.mean(mixed_pairs)]\n",
    "yerrs = [\n",
    "    np.std(ngb_pairs)/len(ngb_pairs)**0.5,\n",
    "    np.std(sb_pairs)/len(sb_pairs)**0.5,\n",
    "    np.std(mixed_pairs)/len(mixed_pairs)**0.5\n",
    "]\n",
    "\n",
    "print('Mean =', yvals)\n",
    "print('Std =', [np.std(ngb_pairs), np.std(sb_pairs), np.std(mixed_pairs)])\n",
    "print('NGB vs SB', stats.ttest_ind(ngb_pairs, sb_pairs, equal_var=False))\n",
    "print('Cohen\\'s d =', cohen_d_for_welch(ngb_pairs, sb_pairs))\n",
    "print('DOF = ', welch_dof(ngb_pairs, sb_pairs))\n",
    "\n",
    "\n",
    "print('\\nNGB vs mixed', stats.ttest_ind(ngb_pairs, mixed_pairs, equal_var=False))\n",
    "print('Cohen\\'s d =', cohen_d_for_welch(ngb_pairs, mixed_pairs))\n",
    "print('DOF = ', welch_dof(ngb_pairs, mixed_pairs))\n",
    "\n",
    "print('\\nSB vs mixed', stats.ttest_ind(sb_pairs, mixed_pairs, equal_var=False))\n",
    "print('Cohen\\'s d =', cohen_d_for_welch(sb_pairs, mixed_pairs))\n",
    "print('DOF = ', welch_dof(sb_pairs, mixed_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twoway_anova(normalized_burst_frequency, ['burst_pair', 'region', 'value']))\n",
    "\n",
    "xpos = np.array([1, 2, 3])\n",
    "\n",
    "region_colors = ['tab:orange', 'tab:blue', 'tab:green']\n",
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "for region_idx, region_key in enumerate(['Ctx-CP', 'Thal-CP', 'Ctx-thal']):\n",
    "    mns = []\n",
    "    errs = []\n",
    "    for burst_pair_key in ['both_ngb', 'both_sb', 'mixed']:\n",
    "        vals = normalized_burst_frequency[burst_pair_key][region_key]\n",
    "\n",
    "        mns.append(np.mean(vals))\n",
    "        errs.append(np.std(vals)/len(vals)**0.5)\n",
    "        \n",
    "    xpos = np.array([1, 3, 5]) + (region_idx-1)/3\n",
    "    plt.bar(xpos, mns, yerr=errs, width=1/3, label=region_key, capsize=3, facecolor=region_colors[region_idx])\n",
    "\n",
    "plt.xticks([1, 3, 5], ['Both NGB', 'Both SB', 'NGB and SB'])\n",
    "plt.ylabel('Normalized frequency')\n",
    "plt.legend()\n",
    "format_plot(plt.gca(), legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_burst_frequency_pairs = {\n",
    "    'both_ngb': [],\n",
    "    'both_sb': [],\n",
    "    'mixed': []\n",
    "}\n",
    "for burst_pair in normalized_burst_frequency:\n",
    "    burst_pair_vals = normalized_burst_frequency[burst_pair]\n",
    "    \n",
    "    for region in burst_pair_vals:\n",
    "        region_vals = burst_pair_vals[region]\n",
    "        normalized_burst_frequency_pairs[burst_pair] += region_vals\n",
    "        \n",
    "ngb_pairs = normalized_burst_frequency_pairs['both_ngb']\n",
    "sb_pairs = normalized_burst_frequency_pairs['both_sb']\n",
    "mixed_pairs = normalized_burst_frequency_pairs['mixed']\n",
    "        \n",
    "print('Mean =', [np.mean(ngb_pairs), np.mean(sb_pairs), np.mean(mixed_pairs)])\n",
    "print('Std =', [np.std(ngb_pairs), np.std(sb_pairs), np.std(mixed_pairs)])\n",
    "print('NGB vs SB', stats.ttest_ind(ngb_pairs, sb_pairs, equal_var=False))\n",
    "print('Cohen\\'s d =', cohen_d_for_welch(ngb_pairs, sb_pairs))\n",
    "print('DOF = ', welch_dof(ngb_pairs, sb_pairs))\n",
    "\n",
    "print('\\nNGB vs mixed', stats.ttest_ind(ngb_pairs, mixed_pairs, equal_var=False))\n",
    "print('Cohen\\'s d =', cohen_d_for_welch(ngb_pairs, mixed_pairs))\n",
    "print('DOF = ', welch_dof(ngb_pairs, mixed_pairs))\n",
    "\n",
    "print('\\nSB vs mixed', stats.ttest_ind(sb_pairs, mixed_pairs, equal_var=False))\n",
    "print('Cohen\\'s d =', cohen_d_for_welch(sb_pairs, mixed_pairs))\n",
    "print('DOF = ', welch_dof(sb_pairs, mixed_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-region spiking activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (recording, channel):\n",
    "    data_range = get_slice_from_s(0, 60*60)\n",
    "    recording_n = recording[\"recording\"]\n",
    "    striatum_channel_n = recording[\"striatum_channel\"]\n",
    "    thalamus_channel_n = recording[\"thalamus_channel\"] if recording[\"thalamus\"] else 0\n",
    "    cortex_channel_n = recording[\"cortex_channel\"]\n",
    "\n",
    "    session = Session(ROOT + recording[\"path\"])\n",
    "    \n",
    "    if channel == 'striatum':\n",
    "        return session.recordings[recording_n].continuous[0].samples[data_range, striatum_channel_n]\n",
    "    elif channel == 'thalamus':\n",
    "        return session.recordings[recording_n].continuous[0].samples[data_range, thalamus_channel_n]\n",
    "    elif channel == 'cortex':\n",
    "        return session.recordings[recording_n].continuous[0].samples[data_range, cortex_channel_n]\n",
    "    \n",
    "def does_chunk_contain_bursts (bursts, chunk_times):\n",
    "    c0, c1 = chunk_times\n",
    "    for burst in bursts:\n",
    "        b0, b1 = burst.time        \n",
    "\n",
    "        ret = max(c0,b0) <= min(c1,b1)\n",
    "        if ret == True:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportion of burst events that have co-occuring spiking elevated above baseline\n",
    "\n",
    "key = \"Thal-CP\"\n",
    "thresh = 2.5\n",
    "min_spks = 0\n",
    "\n",
    "proportion_cooccuring_spikes = []\n",
    "\n",
    "for recording_idx, recording in enumerate(rms_processed_recordings):\n",
    "    print(recording['path'], recording_idx, '/', len(rms_processed_recordings))\n",
    "    \n",
    "    if not \"thalamus_bursts\" in recording:\n",
    "        continue\n",
    "    \n",
    "    cortex_data = load_data (recording, 'thalamus')\n",
    "    striatum_data = load_data (recording, 'striatum')\n",
    "    \n",
    "    co_spiking_count = 0\n",
    "    tot_count = 0\n",
    "\n",
    "    # By burst type\n",
    "    for burst_pair in cooccuring_events[key]:\n",
    "        if not burst_pair[0] in recording[\"thalamus_bursts\"]:\n",
    "            continue\n",
    "            \n",
    "        ctx_burst, cp_burst = burst_pair\n",
    "        one_s = SAMPLING_RATE\n",
    "\n",
    "        len_ctx = len(ctx_burst.data)\n",
    "        baseline_ctx = cortex_data[ctx_burst.time[0]-len_ctx-one_s:ctx_burst.time[0]-one_s]\n",
    "        if not len(baseline_ctx):\n",
    "            continue\n",
    "\n",
    "        len_cp = len(cp_burst.data)\n",
    "        baseline_cp = striatum_data[cp_burst.time[0]-len_cp-one_s:cp_burst.time[0]-one_s]\n",
    "        if not len(baseline_cp):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        spike_times_ctx, _ = detect_MUA (ctx_burst.data, 5, silent=True)\n",
    "        spike_times_ctx_baseline, _ = detect_MUA (baseline_ctx, 5, silent=True)\n",
    "        \n",
    "        spike_times_cp, _ = detect_MUA (cp_burst.data, 5, silent=True)\n",
    "        spike_times_cp_baseline, _ = detect_MUA (baseline_cp, 5, silent=True)\n",
    "\n",
    "        if (len(spike_times_ctx)>=min_spks and len(spike_times_cp)>=min_spks):\n",
    "            if (len(spike_times_ctx)>thresh*len(spike_times_ctx_baseline)) and \\\n",
    "                    (len(spike_times_cp)>thresh*len(spike_times_cp_baseline)): \n",
    "                co_spiking_count += 1\n",
    "            if (len(spike_times_ctx)>thresh*len(spike_times_ctx_baseline)) or \\\n",
    "                (len(spike_times_cp)>thresh*len(spike_times_cp_baseline)): \n",
    "                tot_count += 1\n",
    "\n",
    "    if tot_count:\n",
    "        proportion_cooccuring_spikes.append(co_spiking_count/tot_count)\n",
    "    else:\n",
    "        proportion_cooccuring_spikes.append(np.nan)\n",
    "    \n",
    "print(np.nanmean(proportion_cooccuring_spikes))\n",
    "print(proportion_cooccuring_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot burst results\n",
    "\n",
    "grouped_spks = {\n",
    "    '5-6': [],\n",
    "    '7-8': [],\n",
    "    '9-10': [],\n",
    "    '11-12': []\n",
    "}\n",
    "filtered_recordings = [r for r in rms_processed_recordings]# if 'thalamus_bursts' in r]\n",
    "\n",
    "for prop_spks, recording in zip(proportion_cooccuring_spikes, filtered_recordings):\n",
    "    prop_spks = prop_spks*100\n",
    "    if recording['age'] == 5 or recording['age'] == 6:\n",
    "        grouped_spks['5-6'].append(prop_spks)\n",
    "    elif recording['age'] == 7 or recording['age'] == 8:\n",
    "        grouped_spks['7-8'].append(prop_spks)\n",
    "    elif recording['age'] == 9 or recording['age'] == 10:\n",
    "        grouped_spks['9-10'].append(prop_spks)\n",
    "    elif recording['age'] == 11 or recording['age'] == 12:\n",
    "        grouped_spks['11-12'].append(prop_spks)\n",
    "\n",
    "mn = [np.nanmean(g) for g in grouped_spks.values()]\n",
    "er = [np.nanstd(g)/len(g)**0.5 for g in grouped_spks.values()]\n",
    "\n",
    "plt.errorbar(grouped_spks.keys(), mn, er)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportion of non-burst events that have co-occuring spiking elevated above baseline\n",
    "\n",
    "key = \"Thal-CP\"\n",
    "thresh = 2.5\n",
    "min_spks = 0\n",
    "\n",
    "proportion_cooccuring_spikes_nonburst = []\n",
    "\n",
    "for recording_idx, recording in enumerate(rms_processed_recordings):\n",
    "    if not \"thalamus_bursts\" in recording:\n",
    "        continue\n",
    "\n",
    "    chunk_len = np.mean([b.time[1]-b.time[0] for b in recording[\"thalamus_bursts\"]])/SAMPLING_RATE\n",
    "\n",
    "    print(recording['path'], recording_idx, '/', len(rms_processed_recordings))\n",
    "        \n",
    "    print('\\tLoading cortex data')\n",
    "    cortex_data = load_data (recording, 'thalamus')[:]\n",
    "    print('\\tLoading thalamus data')\n",
    "    striatum_data = load_data (recording, 'striatum')[:]\n",
    "    \n",
    "    co_spiking_count = 0\n",
    "    tot_count = 0\n",
    "    \n",
    "    for t in range(0, len(cortex_data), int(chunk_len*SAMPLING_RATE)):\n",
    "        ctx_chunk = cortex_data[t:t+int(chunk_len*SAMPLING_RATE)]\n",
    "        ctx_basel = cortex_data[t-int((chunk_len+1)*SAMPLING_RATE):t-SAMPLING_RATE]\n",
    "        \n",
    "        cp_chunk = striatum_data[t:t+int(chunk_len*SAMPLING_RATE)]\n",
    "        cp_basel = striatum_data[t-int((chunk_len+1)*SAMPLING_RATE):t-SAMPLING_RATE]\n",
    "        \n",
    "        should_continue = False\n",
    "        for d in [ctx_chunk, ctx_basel, cp_chunk, cp_basel]:\n",
    "            if not len(d):\n",
    "                should_continue = True\n",
    "        if should_continue:\n",
    "            continue\n",
    "            \n",
    "        if does_chunk_contain_bursts(recording[\"thalamus_bursts\"], [t-(chunk_len+1)*SAMPLING_RATE, t+chunk_len*SAMPLING_RATE]):\n",
    "            continue\n",
    "        if does_chunk_contain_bursts(recording[\"striatum_bursts\"], [t-(chunk_len+1)*SAMPLING_RATE, t+chunk_len*SAMPLING_RATE]):\n",
    "            continue\n",
    "        \n",
    "        spike_times_ctx, _ = detect_MUA (ctx_chunk, 5, silent=True)\n",
    "        spike_times_ctx_baseline, _ = detect_MUA (ctx_basel, 5, silent=True)\n",
    "        \n",
    "        spike_times_cp, _ = detect_MUA (cp_chunk, 5, silent=True)\n",
    "        spike_times_cp_baseline, _ = detect_MUA (cp_basel, 5, silent=True)\n",
    "\n",
    "        if (len(spike_times_ctx)>=min_spks and len(spike_times_cp)>=min_spks):\n",
    "            if (len(spike_times_ctx)>thresh*len(spike_times_ctx_baseline)) and \\\n",
    "                    (len(spike_times_cp)>thresh*len(spike_times_cp_baseline)): \n",
    "                co_spiking_count += 1\n",
    "            if (len(spike_times_ctx)>thresh*len(spike_times_ctx_baseline)) or \\\n",
    "                (len(spike_times_cp)>thresh*len(spike_times_cp_baseline)): \n",
    "                tot_count += 1\n",
    "\n",
    "    if tot_count:\n",
    "        proportion_cooccuring_spikes_nonburst.append(co_spiking_count/tot_count)\n",
    "    else:\n",
    "        proportion_cooccuring_spikes_nonburst.append(np.nan)\n",
    "    \n",
    "print(np.nanmean(proportion_cooccuring_spikes_nonburst))\n",
    "print(proportion_cooccuring_spikes_nonburst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot non-bursts results\n",
    "\n",
    "grouped_spks_nonburst = {\n",
    "    '5-6': [],\n",
    "    '7-8': [],\n",
    "    '9-10': [],\n",
    "    '11-12': []\n",
    "}\n",
    "filtered_recordings = [r for r in rms_processed_recordings if 'thalamus_bursts' in r]\n",
    "\n",
    "for prop_spks, recording in zip(proportion_cooccuring_spikes_nonburst, filtered_recordings):\n",
    "    prop_spks = prop_spks*100\n",
    "    if recording['age'] == 5 or recording['age'] == 6:\n",
    "        grouped_spks_nonburst['5-6'].append(prop_spks)\n",
    "    elif recording['age'] == 7 or recording['age'] == 8:\n",
    "        grouped_spks_nonburst['7-8'].append(prop_spks)\n",
    "    elif recording['age'] == 9 or recording['age'] == 10:\n",
    "        grouped_spks_nonburst['9-10'].append(prop_spks)\n",
    "    elif recording['age'] == 11 or recording['age'] == 12:\n",
    "        grouped_spks_nonburst['11-12'].append(prop_spks)\n",
    "\n",
    "mn_nonburst = [np.nanmean(g) for g in grouped_spks_nonburst.values()]\n",
    "er_nonburst = [np.nanstd(g)/len(g)**0.5 for g in grouped_spks_nonburst.values()]\n",
    "\n",
    "plt.errorbar(grouped_spks.keys(), mn, er, label='Burst events')\n",
    "plt.errorbar(grouped_spks_nonburst.keys(), mn_nonburst, er_nonburst, label='Non-burst periods')\n",
    "plt.legend()\n",
    "plt.xlabel('Age (post-natal days)')\n",
    "plt.ylabel('% events with spiking activtiy\\nacross both regions')\n",
    "format_plot(plt.gca(), legend=True)\n",
    "plt.show()\n",
    "\n",
    "mn, mn_nonburst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-spectral coherence over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-spectral coherence over time\n",
    "\n",
    "def align_overlapping_bursts (burst_a, burst_b):\n",
    "    start_overlap = max(burst_a.time[0], burst_b.time[0])\n",
    "    end_overlap = min(burst_a.time[1], burst_b.time[1])\n",
    "    \n",
    "    \n",
    "    start_a = start_overlap-burst_a.time[0]\n",
    "    end_a = start_a + (end_overlap-start_overlap)\n",
    "    start_b = start_overlap-burst_b.time[0]\n",
    "    end_b = start_b + (end_overlap-start_overlap)\n",
    "    \n",
    "    burst_a_trimmed = burst_a.data[start_a:end_a]\n",
    "    burst_b_trimmed = burst_b.data[start_b:end_b]\n",
    "    \n",
    "    return (\n",
    "        burst_a_trimmed,\n",
    "        burst_b_trimmed,\n",
    "        get_xticks(slice(start_overlap, end_overlap))\n",
    "    )\n",
    "\n",
    "csc_over_time_ngb = {\n",
    "    '5-6': [],\n",
    "    '7-8': [],\n",
    "    '9-10': [],\n",
    "    '11-12': []\n",
    "}\n",
    "csc_over_time_sb = {\n",
    "    '5-6': [],\n",
    "    '7-8': [],\n",
    "    '9-10': [],\n",
    "    '11-12': []\n",
    "}\n",
    "\n",
    "window_size = 0.5\n",
    "window = int(SAMPLING_RATE*window_size)\n",
    "overlap = int(SAMPLING_RATE*window_size*0)\n",
    "\n",
    "for burst_pair_idx, burst_pair in enumerate(cooccuring_events[\"Ctx-thal\"]):\n",
    "    burst_a, burst_b = burst_pair\n",
    "    if not hasattr(burst_a, 'age') or not hasattr(burst_b, 'age'):\n",
    "        continue\n",
    "        \n",
    "    if burst_a.age < 7:\n",
    "        age = '5-6'\n",
    "    elif burst_a.age >= 7 and burst_a.age < 9:\n",
    "        age = '7-8'\n",
    "    elif burst_a.age >= 9 and burst_a.age < 11:\n",
    "        age = '9-10'\n",
    "    elif burst_a.age >= 11 and burst_a.age < 13:\n",
    "        age = '11-12'\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    a, b, _ = align_overlapping_bursts(burst_a, burst_b)\n",
    "    \n",
    "    if (burst_pair_idx+1) % 100 == 0:\n",
    "        print('Burst pair', burst_pair_idx+1)\n",
    "\n",
    "    a = butter_bandpass_filter(a, 4, 80)\n",
    "    b = butter_bandpass_filter(b, 4, 80)\n",
    "    \n",
    "    if len(a)/SAMPLING_RATE < 0.5:\n",
    "        continue\n",
    "\n",
    "    f, Cxy = signal.coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "    f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "    \n",
    "    if np.mean(Cxy) > 0.8:\n",
    "        continue\n",
    "\n",
    "    if burst_a in cortex_ngb and burst_b in thalamus_ngb:\n",
    "        csc_over_time_ngb[age].append(np.mean(Cxy))\n",
    "    elif burst_a in cortex_sb and burst_b in thalamus_sb:\n",
    "        csc_over_time_sb[age].append(np.mean(Cxy))\n",
    "        \n",
    "x = np.arange(4)\n",
    "x_ticks = [k for k in csc_over_time_ngb.keys()]\n",
    "\n",
    "y_mn_ngb = [np.mean(v) for v in csc_over_time_ngb.values()]\n",
    "y_er_ngb = [np.std(v)/len(v)**0.5 for v in csc_over_time_ngb.values()]\n",
    "\n",
    "y_mn_sb = [np.mean(v) for v in csc_over_time_sb.values()]\n",
    "y_er_sb = [np.std(v)/len(v)**0.5 for v in csc_over_time_sb.values()]\n",
    "\n",
    "plt.errorbar(x, y_mn_sb, yerr=y_er_sb, label='SB', c='tab:red')\n",
    "plt.errorbar(x, y_mn_ngb, yerr=y_er_ngb, label='NGB', c='tab:blue')\n",
    "plt.legend()\n",
    "plt.xticks(x, x_ticks)\n",
    "plt.xlabel('Age (postnatal days)')\n",
    "plt.ylabel('Mean CSC')\n",
    "format_plot(plt.gca(), legend=True)\n",
    "plt.show()\n",
    "\n",
    "csc_over_time_data = {\n",
    "    'NGB': csc_over_time_ngb,\n",
    "    'SB': csc_over_time_sb\n",
    "}\n",
    "print(twoway_anova(csc_over_time_data, ['burst_type', 'age', 'value']))\n",
    "\n",
    "print('NGB 5-6 mean', np.mean(csc_over_time_ngb['5-6']), 'std', np.std(csc_over_time_ngb['5-6']))\n",
    "print('NB 11-12 mean', np.mean(csc_over_time_ngb['11-12']), 'std', np.std(csc_over_time_ngb['11-12']))\n",
    "print('SB 5-6 mean', np.mean(csc_over_time_sb['5-6']), 'std', np.std(csc_over_time_sb['5-6']))\n",
    "print('SB 11-12 mean', np.mean(csc_over_time_sb['11-12']), 'std', np.std(csc_over_time_sb['11-12']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-spectal coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_overlapping_bursts_full (burst_a, burst_b, burst_a_channel_key, burst_b_channel_key):\n",
    "    start = min(burst_a.time[0], burst_b.time[0])\n",
    "    end = max(burst_a.time[1], burst_b.time[1])\n",
    "    \n",
    "    time_slice = slice(start, end)\n",
    "    \n",
    "    for recording in RECORDINGS:\n",
    "        recording_n = recording[\"recording\"]\n",
    "        \n",
    "        if recording[\"path\"] == burst_a.recording_path:\n",
    "            session = Session(ROOT + recording[\"path\"])\n",
    "            data_a = session.recordings[recording_n].continuous[0].samples[time_slice, recording[burst_a_channel_key]]\n",
    "            \n",
    "        if recording[\"path\"] == burst_b.recording_path:\n",
    "            session = Session(ROOT + recording[\"path\"])\n",
    "            data_b = session.recordings[recording_n].continuous[0].samples[time_slice, recording[burst_b_channel_key]]\n",
    "    \n",
    "    return data_a, data_b\n",
    "\n",
    "window_size = 0.5\n",
    "window = int(SAMPLING_RATE*window_size)\n",
    "overlap = int(SAMPLING_RATE*window_size*0)\n",
    "\n",
    "Cxy_arr_shuffled_ngb = []\n",
    "Cxy_arr_ngb = []\n",
    "\n",
    "Cxy_arr_shuffled_sb = []\n",
    "Cxy_arr_sb = []\n",
    "\n",
    "mean_coherence_ngb = []\n",
    "mean_coherence_shuffled_ngb = []\n",
    "\n",
    "mean_coherence_sb = []\n",
    "mean_coherence_shuffled_sb = []\n",
    "\n",
    "bursts_a_ngb = []\n",
    "bursts_b_ngb = []\n",
    "\n",
    "bursts_a_sb = []\n",
    "bursts_b_sb = []\n",
    "\n",
    "for burst_pair_idx, burst_pair in enumerate(cooccuring_events[\"Ctx-CP\"]):\n",
    "    burst_a, burst_b = burst_pair\n",
    "    if not hasattr(burst_a, 'age') or not hasattr(burst_b, 'age'):\n",
    "        continue\n",
    "        \n",
    "    a, b, _ = align_overlapping_bursts(burst_a, burst_b) #, \"cortex_channel\", \"striatum_channel\")\n",
    "    \n",
    "    if (burst_pair_idx+1) % 100 == 0:\n",
    "        print('Burst pair', burst_pair_idx+1)\n",
    "\n",
    "    a = butter_bandpass_filter(a, 4, 80)\n",
    "    b = butter_bandpass_filter(b, 4, 80)\n",
    "    \n",
    "    if len(a)/SAMPLING_RATE < 0.5:\n",
    "        continue\n",
    "\n",
    "    if burst_a in cortex_ngb and burst_b in striatum_ngb:     \n",
    "        #f, Cxy = imag_coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "        f, Cxy = signal.coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "\n",
    "        if np.mean(Cxy) <= 0.8:        \n",
    "            f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "\n",
    "            Cxy_arr_ngb.append(Cxy)\n",
    "            mean_coherence_ngb.append(np.mean(Cxy))\n",
    "            bursts_a_ngb.append(a)\n",
    "            bursts_b_ngb.append(b)\n",
    "    elif burst_a in cortex_sb and burst_b in striatum_sb:\n",
    "        #f, Cxy = imag_coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "        f, Cxy = signal.coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "        f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "\n",
    "        if np.mean(Cxy) <= 0.8:\n",
    "            Cxy_arr_sb.append(Cxy)\n",
    "            mean_coherence_sb.append(np.mean(Cxy))\n",
    "            bursts_a_sb.append(a)\n",
    "            bursts_b_sb.append(b)\n",
    "\n",
    "for i in range(1000):\n",
    "    if (i+1) % 10 == 0:\n",
    "        print('Shuffle iteration', i+1)\n",
    "    \n",
    "    burst_pairs_shuffled_ngb = np.array([bursts_a_ngb, bursts_b_ngb], dtype=object).T\n",
    "    burst_pairs_shuffled_sb = np.array([bursts_a_sb, bursts_b_sb], dtype=object).T\n",
    "\n",
    "    Cxy_shuffled_inner_ngb = []\n",
    "    Cxy_shuffled_inner_sb = []\n",
    "    \n",
    "    for burst_pair in burst_pairs_shuffled_ngb:\n",
    "        a, b = np.random.permutation(burst_pair[0]), np.random.permutation(burst_pair[1])\n",
    "        \n",
    "        f, Cxy = signal.coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "        f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "            \n",
    "        Cxy_shuffled_inner_ngb.append(Cxy)\n",
    "        \n",
    "    for burst_pair in burst_pairs_shuffled_sb:        \n",
    "        a, b = np.random.permutation(burst_pair[0]), np.random.permutation(burst_pair[1])\n",
    "         \n",
    "        f, Cxy = imag_coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "        f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "        \n",
    "        Cxy_shuffled_inner_sb.append(Cxy)\n",
    "    \n",
    "    Cxy_shuffled_inner_ngb_mean = np.mean(Cxy_shuffled_inner_ngb, axis=0)\n",
    "    Cxy_shuffled_inner_sb_mean = np.mean(Cxy_shuffled_inner_sb, axis=0)\n",
    "    \n",
    "    Cxy_arr_shuffled_ngb.append(Cxy_shuffled_inner_ngb_mean)\n",
    "    Cxy_arr_shuffled_sb.append(Cxy_shuffled_inner_sb_mean)\n",
    "    \n",
    "    mean_coherence_shuffled_ngb.append(np.mean(Cxy_shuffled_inner_ngb_mean))\n",
    "    mean_coherence_shuffled_sb.append(np.mean(Cxy_shuffled_inner_sb_mean))\n",
    "    \n",
    "# Bar plot\n",
    "y = [\n",
    "    np.mean(mean_coherence_ngb),\n",
    "    np.mean(mean_coherence_sb),\n",
    "]\n",
    "yerr = [\n",
    "    np.std(mean_coherence_ngb)/len(mean_coherence_ngb)**0.5,\n",
    "    np.std(mean_coherence_sb)/len(mean_coherence_sb)**0.5,\n",
    "]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:red\",\n",
    "]\n",
    "bars = plt.bar([\"NGB\", \"SB\"], y, yerr=yerr, capsize=5)\n",
    "for idx, bar_i in enumerate(bars):\n",
    "    bar_i.set_color(colors[idx])\n",
    "plt.ylabel('Mean coherence')\n",
    "format_plot(plt.gca(), legend=False)\n",
    "plt.show()\n",
    "print('ngb versus sb', stats.ttest_ind(mean_coherence_ngb, mean_coherence_sb, equal_var=False))\n",
    "print('ngb', stats.ttest_ind(mean_coherence_ngb, mean_coherence_shuffled_ngb, equal_var=False))\n",
    "print('sb', stats.ttest_ind(mean_coherence_sb, mean_coherence_shuffled_sb, equal_var=False))\n",
    "\n",
    "# Coherence plot\n",
    "mean_ngb = np.nanmean(Cxy_arr_ngb, axis=0)\n",
    "stderr_ngb = np.nanstd(Cxy_arr_ngb, axis=0) / len(Cxy_arr_ngb)**0.5\n",
    "mean_sb = np.nanmean(Cxy_arr_sb, axis=0)\n",
    "stderr_sb = np.nanstd(Cxy_arr_sb, axis=0) / len(Cxy_arr_ngb)**0.5\n",
    "\n",
    "plt.plot(f, mean_ngb, label='NGB', c='tab:blue')\n",
    "plt.fill_between(f, mean_ngb+stderr_ngb, mean_ngb-stderr_ngb, alpha=0.5, facecolor='tab:blue')\n",
    "\n",
    "shuffle_idx_ngb = np.where(mean_coherence_shuffled_ngb == np.percentile(mean_coherence_shuffled_ngb, 95, interpolation='nearest'))[0][0]\n",
    "shuffled_95_percentile_ngb = Cxy_arr_shuffled_ngb[shuffle_idx_ngb]\n",
    "plt.plot(f, shuffled_95_percentile_ngb, '--', label='Shuffled NGB', c='tab:blue')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Coherence')\n",
    "plt.legend()\n",
    "format_plot(plt.gca())\n",
    "plt.show()\n",
    "\n",
    "plt.plot(f, mean_sb, label='SB', c='tab:red')\n",
    "plt.fill_between(f, mean_sb+stderr_sb, mean_sb-stderr_sb, alpha=0.5, facecolor='tab:red')\n",
    "\n",
    "shuffle_idx_sb = np.where(mean_coherence_shuffled_sb == np.percentile(mean_coherence_shuffled_sb, 95, interpolation='nearest'))[0][0]\n",
    "shuffled_95_percentile_sb = Cxy_arr_shuffled_sb[shuffle_idx_sb]\n",
    "plt.plot(f, shuffled_95_percentile_sb, '--', label='Shuffled SB', c='tab:red')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Coherence')\n",
    "plt.legend()\n",
    "format_plot(plt.gca())\n",
    "\n",
    "print('SB', f[np.argmax(mean_sb)])\n",
    "print('NGB', f[np.argmax(mean_ngb)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-correlation lag of instantaneous amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"Ctx-CP\"\n",
    "\n",
    "def get_xcorr_null_dist (a, b, iterations=1000):\n",
    "    max_xcorr = []\n",
    "    for i in range(iterations):\n",
    "        shift = int(np.random.uniform(1*SAMPLING_RATE, len(a)))\n",
    "    \n",
    "        a_copy = a[shift:]\n",
    "        b_copy = b[:-shift]\n",
    "        \n",
    "        cross_corr = correlate_template(\n",
    "            a_copy, b_copy, mode='full', normalize=None, demean=False\n",
    "        )**2\n",
    "        \n",
    "        two_hundred_ms = int(SAMPLING_RATE*0.2)\n",
    "\n",
    "        max_xcorr.append(np.max(cross_corr))\n",
    "    return max_xcorr\n",
    "\n",
    "max_lag = []\n",
    "\n",
    "for recording_idx, recording in enumerate(rms_processed_recordings[-4:]):\n",
    "    print(recording['path'], recording_idx, '/', len(rms_processed_recordings))\n",
    "    \n",
    "    #if not \"thalamus_bursts\" in recording:\n",
    "    #    continue\n",
    "    \n",
    "    region_a_data = load_data (recording, 'cortex')\n",
    "    region_b_data = load_data (recording, 'striatum')\n",
    "    \n",
    "    burst_count = 0\n",
    "    total_bursts = len([b for b in cooccuring_events[key] if b[0] in recording[\"cortex_bursts\"]])\n",
    "    \n",
    "    # By burst type\n",
    "    for burst_pair in cooccuring_events[key]:\n",
    "        if not burst_pair[0] in recording[\"cortex_bursts\"]:\n",
    "            continue\n",
    "        \n",
    "        burst_count += 1\n",
    "        print('\\tBurst', burst_count, '/', total_bursts)\n",
    "        \n",
    "        burst_a, burst_b = burst_pair\n",
    "        start_t = min(burst_a.time[0], burst_b.time[0])\n",
    "        end_t = max(burst_a.time[1], burst_b.time[1])\n",
    "        \n",
    "        a_data = region_a_data[start_t:end_t]\n",
    "        b_data = region_b_data[start_t:end_t]\n",
    "        \n",
    "        a_data = butter_bandpass_filter(a_data, 4, 16)\n",
    "        b_data = butter_bandpass_filter(b_data, 4, 16)\n",
    "        \n",
    "        if len(a_data) < SAMPLING_RATE*3:\n",
    "            continue\n",
    "    \n",
    "        analytic_signal_a = signal.hilbert(a_data)\n",
    "        amplitude_a = np.abs(analytic_signal_a)\n",
    "        amplitude_a = amplitude_a - np.mean(amplitude_a)\n",
    "\n",
    "        analytic_signal_b = signal.hilbert(b_data)\n",
    "        amplitude_b = np.abs(analytic_signal_b)\n",
    "        amplitude_b = amplitude_b - np.mean(amplitude_b)\n",
    "\n",
    "        cross_corr = correlate_template(\n",
    "            amplitude_a, amplitude_b, mode='full', normalize=None, demean=False\n",
    "        )**2\n",
    "        \n",
    "        two_hundred_ms = int(SAMPLING_RATE*0.2)\n",
    "        start_t_xcorr = (len(cross_corr)-two_hundred_ms)//2\n",
    "        \n",
    "        lags = np.arange(-len(cross_corr)//2, len(cross_corr))/SAMPLING_RATE\n",
    "        lags_centre = lags[start_t_xcorr:start_t_xcorr+two_hundred_ms]\n",
    "        cross_corr_centre = cross_corr[start_t_xcorr:start_t_xcorr+two_hundred_ms]\n",
    "                \n",
    "        max_xcorr = np.max(cross_corr_centre)\n",
    "        null_dist = get_xcorr_null_dist(amplitude_a, amplitude_b)\n",
    "                \n",
    "        if max_xcorr> np.percentile(null_dist, 97.5):\n",
    "            max_lag.append(lags_centre[np.argmax(cross_corr_centre)])\n",
    "            \n",
    "    plt.hist(max_lag)\n",
    "    plt.show()\n",
    "    print(np.mean(max_lag)*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-correlation lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_ROOT = ''\n",
    "\n",
    "# Get cross-spectral coherence for burst pairs    \n",
    "window_size = 0.5\n",
    "window = int(SAMPLING_RATE*window_size)\n",
    "overlap = int(SAMPLING_RATE*window_size*0)\n",
    "\n",
    "xpos_arr = None\n",
    "cross_corr_arr_test = []\n",
    "peaks_arr_test = []\n",
    "\n",
    "cross_corr_arr_control = []\n",
    "peaks_arr_control = []\n",
    "\n",
    "bursts_a = []\n",
    "bursts_b = []\n",
    "\n",
    "events = np.concatenate([cooccuring_events['Ctx-CP']])\n",
    "\n",
    "for burst_pair_idx, burst_pair in enumerate(events):\n",
    "    if (burst_pair_idx+1) % 10 == 0:\n",
    "        print( 'Burst pair {}/{}'.format(burst_pair_idx+1, len(events) ))\n",
    "\n",
    "    burst_a, burst_b = burst_pair\n",
    "        \n",
    "    if not (burst_a in cortex_ngb and burst_b in striatum_ngb):\n",
    "        continue\n",
    "    if burst_a.age > 8:\n",
    "        continue\n",
    "        \n",
    "    a, b, ticks = align_overlapping_bursts (burst_a, burst_b)\n",
    "    \n",
    "    bursts_a.append(a)\n",
    "    bursts_b.append(b)\n",
    "    \n",
    "    if len(a) < 0.5*SAMPLING_RATE:\n",
    "        continue\n",
    "\n",
    "    f, Cxy = signal.coherence(a, b, fs=SAMPLING_RATE, nperseg=window, noverlap=overlap)\n",
    "    f, Cxy = get_psd_in_range((f, Cxy), [4, 80])\n",
    "    \n",
    "    if np.mean(Cxy) > 0.8:\n",
    "        continue\n",
    "            \n",
    "    xpos, cross_corr = get_lags(a, b, [16, 40], prewhiten=True)\n",
    "    xpos_arr = xpos\n",
    "    \n",
    "    cross_corr_arr_test.append(cross_corr)\n",
    "    \n",
    "    peaks_arr_test.append(xpos[np.argmax(cross_corr)])\n",
    "    \n",
    "    xpos, cross_corr = get_lags(a, b, [4, 16], prewhiten=True)\n",
    "    xpos_arr = xpos\n",
    "    cross_corr_arr_control.append(cross_corr)\n",
    "    peaks_arr_control.append(xpos[np.argmax(cross_corr)])\n",
    "    \n",
    "    \n",
    "means_test = np.mean(cross_corr_arr_test, axis=0)\n",
    "stderrs_test = np.std(cross_corr_arr_test, axis=0) / len(cross_corr_arr_test)**0.5\n",
    "means_control = np.mean(cross_corr_arr_control, axis=0)\n",
    "stderrs_control = np.std(cross_corr_arr_control, axis=0) / len(cross_corr_arr_control)**0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Line plot\n",
    "plt.plot(xpos_arr, means_test, label='16-40 Hz', c='tab:purple')\n",
    "plt.fill_between(xpos_arr, means_test-stderrs_test, means_test+stderrs_test, alpha=0.25, facecolor='tab:purple')\n",
    "means_test_max = np.max(means_test)\n",
    "\n",
    "plt.plot(xpos_arr, means_control, label='4-16 Hz', c='tab:cyan')\n",
    "plt.fill_between(xpos_arr, means_control-stderrs_control, means_control+stderrs_control, alpha=0.25, facecolor='tab:cyan')\n",
    "means_control_max = np.max(means_control)\n",
    "\n",
    "plt.ylabel('Squared cross-correlation')\n",
    "plt.xlabel('Lag (ms)')\n",
    "plt.legend()\n",
    "format_plot(plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bar plot\n",
    "means_test = np.mean(peaks_arr_test, axis=0)\n",
    "stderrs_test = np.std(peaks_arr_test, axis=0) / len(peaks_arr_test)**0.5\n",
    "means_control = np.mean(peaks_arr_control, axis=0)\n",
    "stderrs_control = np.std(peaks_arr_control, axis=0) / len(peaks_arr_control)**0.5\n",
    "\n",
    "bars = plt.bar([0, 1], [means_test, means_control], yerr=[stderrs_test, stderrs_control], capsize=5, facecolor='dimgray')\n",
    "bars[0].set_color('tab:purple')\n",
    "bars[1].set_color('tab:cyan')\n",
    "plt.xticks([0, 1], [\"16-40 Hz\", \"4-16 Hz\"])\n",
    "plt.ylabel('Lag (ms)')\n",
    "format_plot(plt.gca(), legend=False)\n",
    "plt.show()\n",
    "\n",
    "print('16-40 Hz', stats.ttest_1samp([p for p in peaks_arr_test if p != 100 and p != -100], popmean=0))\n",
    "print('4-16 Hz', stats.ttest_1samp(peaks_arr_control, popmean=0))\n",
    "\n",
    "# Histogram\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "axs[0].hist(peaks_arr_test, bins=100);\n",
    "axs[0].set_title('16-40 Hz filtered, mean lag = {}'.format(np.mean(peaks_arr_test)));\n",
    "axs[1].hist(peaks_arr_control, bins=100);\n",
    "axs[1].set_title('4-16 Hz filtered, mean lag = {}'.format(np.mean(peaks_arr_control)));\n",
    "format_plot(plt.gca(), legend=False)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk]",
   "language": "python",
   "name": "conda-env-allensdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
